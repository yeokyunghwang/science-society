{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dabadec-09da-4840-9eeb-f6741432b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"`tokenizer` is deprecated and will be removed in version 5.0.0\"\n",
    ")\n",
    "\n",
    "import transformers\n",
    "transformers.utils.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6537b2ec-c460-4ce3-b43f-ce9383a9a5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/news_1990.txt\n",
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/paper_1990.txt\n",
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/news_1991.txt\n",
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/paper_1991.txt\n",
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/news_1992.txt\n",
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/paper_1992.txt\n",
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/news_1993.txt\n",
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/paper_1993.txt\n",
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/news_1994.txt\n",
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/paper_1994.txt\n",
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/news_1995.txt\n",
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/paper_1995.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /root/science-society\n",
    "\n",
    "START_MODE=\"uniform\"\n",
    "\n",
    "if [ \"${START_MODE}\" = \"per_node\" ]; then\n",
    "  MODE_TAG=\"start=${START_MODE}__scheme=${PER_NODE_SCHEME}\"\n",
    "else\n",
    "  MODE_TAG=\"start=${START_MODE}\"\n",
    "fi\n",
    "\n",
    "CORPUS_DIR=\"./corpus/${MODE_TAG}\"\n",
    "MAP_DIR=\"./tokenizer/${MODE_TAG}\"\n",
    "mkdir -p \"${CORPUS_DIR}\" \"${MAP_DIR}\"\n",
    "\n",
    "for Y in 1990 1991 1992 1993 1994 1995; do\n",
    "  python ./scripts/make_walk_corpus_encoded.py \\\n",
    "    --pkl ./data/news/news_network_${Y}_m0.0-M1.0.pkl \\\n",
    "    --out \"${CORPUS_DIR}/news_${Y}.txt\" \\\n",
    "    --walk_length 20 --num_walks 20000 --seed 42 \\\n",
    "    --start_mode \"${START_MODE}\"\\\n",
    "    --mapping_json \"${MAP_DIR}/news_mapping_${Y}.json\"\n",
    "\n",
    "  python ./scripts/make_walk_corpus_encoded.py \\\n",
    "    --pkl ./data/paper/paper_network_${Y}_m0.0-M0.5.pkl \\\n",
    "    --out \"${CORPUS_DIR}/paper_${Y}.txt\" \\\n",
    "    --walk_length 20 --num_walks 20000 --seed 42 \\\n",
    "    --start_mode \"${START_MODE}\" \\\n",
    "    --mapping_json \"${MAP_DIR}/paper_mapping_${Y}.json\"\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb09fdaf-8ac6-4649-9198-a192689ec451",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1151759.23 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved news_1990 -> ./datasets/start=uniform/news_1990 (n=20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1516872.45 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved paper_1990 -> ./datasets/start=uniform/paper_1990 (n=20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1513833.94 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved news_1991 -> ./datasets/start=uniform/news_1991 (n=20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1525922.80 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved paper_1991 -> ./datasets/start=uniform/paper_1991 (n=20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1577873.75 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved news_1992 -> ./datasets/start=uniform/news_1992 (n=20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1523096.81 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved paper_1992 -> ./datasets/start=uniform/paper_1992 (n=20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1574467.99 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved news_1993 -> ./datasets/start=uniform/news_1993 (n=20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1497350.73 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved paper_1993 -> ./datasets/start=uniform/paper_1993 (n=20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1545261.76 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved news_1994 -> ./datasets/start=uniform/news_1994 (n=20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1484761.94 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved paper_1994 -> ./datasets/start=uniform/paper_1994 (n=20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1491944.65 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved news_1995 -> ./datasets/start=uniform/news_1995 (n=20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1519565.25 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved paper_1995 -> ./datasets/start=uniform/paper_1995 (n=20000)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /root/science-society\n",
    "\n",
    "START_MODE=\"uniform\"\n",
    "\n",
    "if [ \"${START_MODE}\" = \"per_node\" ]; then\n",
    "  MODE_TAG=\"start=${START_MODE}__scheme=${PER_NODE_SCHEME}\"\n",
    "else\n",
    "  MODE_TAG=\"start=${START_MODE}\"\n",
    "fi\n",
    "\n",
    "CORPUS_DIR=\"./corpus/${MODE_TAG}\"\n",
    "DATASET_DIR=\"./datasets/${MODE_TAG}\"\n",
    "mkdir -p \"${DATASET_DIR}\"\n",
    "\n",
    "python scripts/make_hf_dataset.py \\\n",
    "  --corpus_root \"${CORPUS_DIR}\" \\\n",
    "  --out_dir \"${DATASET_DIR}\" \\\n",
    "  --years 1990 1991 1992 1993 1994 1995 \\\n",
    "  --domains news paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fcd7665-f835-445e-b3cb-475ceca01b0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vocab] loaded node tokens: 22577\n",
      "[tokenizer] added tokens: 22577 (new vocab size=50345)\n",
      "[init] initialized added node token embeddings: 19823, fallback_to_UNK: 0\n",
      "[mask] node_token_ids in tokenizer: 22577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3095/3095 [03:06<00:00, 16.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.4658, 'grad_norm': 9.799673080444336, 'learning_rate': 4.975936748023376e-05, 'epoch': 0.32}\n",
      "{'loss': 6.2519, 'grad_norm': 7.620432376861572, 'learning_rate': 4.6321760055001723e-05, 'epoch': 0.65}\n",
      "{'loss': 5.964, 'grad_norm': 8.510808944702148, 'learning_rate': 4.288415262976968e-05, 'epoch': 0.97}\n",
      "{'loss': 5.8287, 'grad_norm': 7.5809760093688965, 'learning_rate': 3.9446545204537646e-05, 'epoch': 1.29}\n",
      "{'loss': 5.6457, 'grad_norm': 8.092015266418457, 'learning_rate': 3.600893777930561e-05, 'epoch': 1.62}\n",
      "{'loss': 5.5564, 'grad_norm': 8.533291816711426, 'learning_rate': 3.257133035407357e-05, 'epoch': 1.94}\n",
      "{'loss': 5.418, 'grad_norm': 10.043675422668457, 'learning_rate': 2.913372292884153e-05, 'epoch': 2.26}\n",
      "{'loss': 5.3086, 'grad_norm': 8.49070930480957, 'learning_rate': 2.569611550360949e-05, 'epoch': 2.58}\n",
      "{'loss': 5.259, 'grad_norm': 8.21644401550293, 'learning_rate': 2.225850807837745e-05, 'epoch': 2.91}\n",
      "{'loss': 5.1515, 'grad_norm': 9.598251342773438, 'learning_rate': 1.8820900653145413e-05, 'epoch': 3.23}\n",
      "{'loss': 5.1346, 'grad_norm': 8.390536308288574, 'learning_rate': 1.5383293227913374e-05, 'epoch': 3.55}\n",
      "{'loss': 5.0668, 'grad_norm': 8.84453010559082, 'learning_rate': 1.1945685802681335e-05, 'epoch': 3.88}\n",
      "{'loss': 5.0086, 'grad_norm': 8.916548728942871, 'learning_rate': 8.508078377449295e-06, 'epoch': 4.2}\n",
      "{'loss': 4.9586, 'grad_norm': 11.337307929992676, 'learning_rate': 5.070470952217257e-06, 'epoch': 4.52}\n",
      "{'loss': 4.9264, 'grad_norm': 9.59706974029541, 'learning_rate': 1.6328635269852184e-06, 'epoch': 4.85}\n",
      "{'train_runtime': 186.9919, 'train_samples_per_second': 529.435, 'train_steps_per_second': 16.552, 'train_loss': 5.511150935701484, 'epoch': 5.0}\n",
      "[done] baseline saved to: ./checkpoints/start=uniform/news_1990_seed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vocab] loaded node tokens: 22577\n",
      "[tokenizer] added tokens: 22577 (new vocab size=50345)\n",
      "[init] initialized added node token embeddings: 19823, fallback_to_UNK: 0\n",
      "[mask] node_token_ids in tokenizer: 22577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3095/3095 [03:07<00:00, 16.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 8.5941, 'grad_norm': 9.487297058105469, 'learning_rate': 4.975936748023376e-05, 'epoch': 0.32}\n",
      "{'loss': 7.517, 'grad_norm': 8.29940414428711, 'learning_rate': 4.6321760055001723e-05, 'epoch': 0.65}\n",
      "{'loss': 7.2814, 'grad_norm': 9.577744483947754, 'learning_rate': 4.288415262976968e-05, 'epoch': 0.97}\n",
      "{'loss': 7.1115, 'grad_norm': 7.894964218139648, 'learning_rate': 3.9446545204537646e-05, 'epoch': 1.29}\n",
      "{'loss': 7.016, 'grad_norm': 9.48759651184082, 'learning_rate': 3.600893777930561e-05, 'epoch': 1.62}\n",
      "{'loss': 6.9868, 'grad_norm': 8.025230407714844, 'learning_rate': 3.257133035407357e-05, 'epoch': 1.94}\n",
      "{'loss': 6.8655, 'grad_norm': 9.795790672302246, 'learning_rate': 2.913372292884153e-05, 'epoch': 2.26}\n",
      "{'loss': 6.7965, 'grad_norm': 8.805621147155762, 'learning_rate': 2.569611550360949e-05, 'epoch': 2.58}\n",
      "{'loss': 6.7957, 'grad_norm': 7.913365364074707, 'learning_rate': 2.225850807837745e-05, 'epoch': 2.91}\n",
      "{'loss': 6.6985, 'grad_norm': 8.156784057617188, 'learning_rate': 1.8820900653145413e-05, 'epoch': 3.23}\n",
      "{'loss': 6.6965, 'grad_norm': 7.826783657073975, 'learning_rate': 1.5383293227913374e-05, 'epoch': 3.55}\n",
      "{'loss': 6.6553, 'grad_norm': 9.162278175354004, 'learning_rate': 1.1945685802681335e-05, 'epoch': 3.88}\n",
      "{'loss': 6.5834, 'grad_norm': 8.906835556030273, 'learning_rate': 8.508078377449295e-06, 'epoch': 4.2}\n",
      "{'loss': 6.5991, 'grad_norm': 9.991645812988281, 'learning_rate': 5.070470952217257e-06, 'epoch': 4.52}\n",
      "{'loss': 6.5285, 'grad_norm': 10.176764488220215, 'learning_rate': 1.6328635269852184e-06, 'epoch': 4.85}\n",
      "{'train_runtime': 187.7783, 'train_samples_per_second': 527.218, 'train_steps_per_second': 16.482, 'train_loss': 6.968027832820073, 'epoch': 5.0}\n",
      "[done] baseline saved to: ./checkpoints/start=uniform/paper_1990_seed\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /root/science-society\n",
    "\n",
    "START_MODE=\"uniform\"\n",
    "\n",
    "if [ \"${START_MODE}\" = \"per_node\" ]; then\n",
    "  MODE_TAG=\"start=${START_MODE}__scheme=${PER_NODE_SCHEME}\"\n",
    "else\n",
    "  MODE_TAG=\"start=${START_MODE}\"\n",
    "fi\n",
    "\n",
    "y=1990\n",
    "DATASET_DIR=\"./datasets/${MODE_TAG}\"\n",
    "CKPT_DIR=\"./checkpoints/${MODE_TAG}\"\n",
    "mkdir -p \"${CKPT_DIR}\"\n",
    "\n",
    "python scripts/train_mlm_preinit.py \\\n",
    "  --dataset_dir \"${DATASET_DIR}/news_${y}\" \\\n",
    "  --node_vocab_txt ./tokenizer/concept_vocab_encoded.txt \\\n",
    "  --output_dir \"${CKPT_DIR}/news_${y}_seed\" \\\n",
    "  --num_train_epochs 5 \\\n",
    "  --learning_rate 5e-5 \\\n",
    "  --mlm_prob 0.15\n",
    "\n",
    "python scripts/train_mlm_preinit.py \\\n",
    "  --dataset_dir \"${DATASET_DIR}/paper_${y}\" \\\n",
    "  --node_vocab_txt ./tokenizer/concept_vocab_encoded.txt \\\n",
    "  --output_dir \"${CKPT_DIR}/paper_${y}_seed\" \\\n",
    "  --num_train_epochs 5 \\\n",
    "  --learning_rate 5e-5 \\\n",
    "  --mlm_prob 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "191fd6d7-3d45-4c5c-b92d-8d91a095855c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[plan]\n",
      "  - 1991: ./datasets/start=uniform/news_1991\n",
      "[vocab] node tokens: 22577\n",
      "\n",
      "==============================\n",
      "[year 1991] init_dir = ./checkpoints/start=uniform/news_1990_seed\n",
      "[year 1991] dataset_dir = ./datasets/start=uniform/news_1991\n",
      "[year 1991] node_token_ids in tokenizer: 22577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 20000/20000 [00:00<00:00, 28260.43 examples/s]\n",
      "100%|██████████| 1238/1238 [01:18<00:00, 15.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.6131, 'grad_norm': 15.475471496582031, 'learning_rate': 8.92519346517627e-06, 'epoch': 0.32}\n",
      "{'loss': 5.9081, 'grad_norm': 15.723024368286133, 'learning_rate': 7.2055030094582974e-06, 'epoch': 0.65}\n",
      "{'loss': 5.7181, 'grad_norm': 14.931378364562988, 'learning_rate': 5.485812553740327e-06, 'epoch': 0.97}\n",
      "{'loss': 5.5019, 'grad_norm': 16.500917434692383, 'learning_rate': 3.7661220980223563e-06, 'epoch': 1.29}\n",
      "{'loss': 5.4637, 'grad_norm': 16.86391830444336, 'learning_rate': 2.0464316423043853e-06, 'epoch': 1.62}\n",
      "{'loss': 5.357, 'grad_norm': 19.0028018951416, 'learning_rate': 3.2674118658641445e-07, 'epoch': 1.94}\n",
      "{'train_runtime': 78.8105, 'train_samples_per_second': 502.471, 'train_steps_per_second': 15.709, 'train_loss': 5.746613140445149, 'epoch': 2.0}\n",
      "[year 1991] saved: ./checkpoints/start=uniform/news_annual/1991\n",
      "\n",
      "[done] all years finished.\n",
      "[done] final checkpoint: ./checkpoints/start=uniform/news_annual/1991\n",
      "[plan]\n",
      "  - 1991: ./datasets/start=uniform/paper_1991\n",
      "[vocab] node tokens: 22577\n",
      "\n",
      "==============================\n",
      "[year 1991] init_dir = ./checkpoints/start=uniform/paper_1990_seed\n",
      "[year 1991] dataset_dir = ./datasets/start=uniform/paper_1991\n",
      "[year 1991] node_token_ids in tokenizer: 22577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 20000/20000 [00:00<00:00, 28075.88 examples/s]\n",
      "100%|██████████| 1238/1238 [01:18<00:00, 15.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.9059, 'grad_norm': 15.247794151306152, 'learning_rate': 8.92519346517627e-06, 'epoch': 0.32}\n",
      "{'loss': 6.7895, 'grad_norm': 13.682376861572266, 'learning_rate': 7.2055030094582974e-06, 'epoch': 0.65}\n",
      "{'loss': 6.7953, 'grad_norm': 14.370524406433105, 'learning_rate': 5.485812553740327e-06, 'epoch': 0.97}\n",
      "{'loss': 6.7622, 'grad_norm': 13.888494491577148, 'learning_rate': 3.7661220980223563e-06, 'epoch': 1.29}\n",
      "{'loss': 6.7942, 'grad_norm': 15.463550567626953, 'learning_rate': 2.0464316423043853e-06, 'epoch': 1.62}\n",
      "{'loss': 6.7655, 'grad_norm': 13.951034545898438, 'learning_rate': 3.2674118658641445e-07, 'epoch': 1.94}\n",
      "{'train_runtime': 78.4688, 'train_samples_per_second': 504.659, 'train_steps_per_second': 15.777, 'train_loss': 6.798774337152287, 'epoch': 2.0}\n",
      "[year 1991] saved: ./checkpoints/start=uniform/paper_annual/1991\n",
      "\n",
      "[done] all years finished.\n",
      "[done] final checkpoint: ./checkpoints/start=uniform/paper_annual/1991\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /root/science-society\n",
    "\n",
    "START_MODE=\"uniform\"\n",
    "\n",
    "if [ \"${START_MODE}\" = \"per_node\" ]; then\n",
    "  MODE_TAG=\"start=${START_MODE}__scheme=${PER_NODE_SCHEME}\"\n",
    "else\n",
    "  MODE_TAG=\"start=${START_MODE}\"\n",
    "fi\n",
    "\n",
    "init_y=1990\n",
    "DATASET_DIR=\"./datasets/${MODE_TAG}\"\n",
    "CKPT_DIR=\"./checkpoints/${MODE_TAG}\"\n",
    "mkdir -p \"${CKPT_DIR}\"\n",
    "\n",
    "d=\"news\"\n",
    "python scripts/train_annual_2stage_preinit.py \\\n",
    "  --init_dir \"${CKPT_DIR}/${d}_${init_y}_seed\" \\\n",
    "  --node_vocab_txt ./tokenizer/concept_vocab_encoded.txt \\\n",
    "  --years 1991 \\\n",
    "  --dataset_template \"${DATASET_DIR}/${d}_{year}\" \\\n",
    "  --output_base_dir \"${CKPT_DIR}/${d}_annual\" \\\n",
    "  --exact_k_masks 1 \\\n",
    "  --num_train_epochs 2 \\\n",
    "  --learning_rate 1e-5 \\\n",
    "\n",
    "d=\"paper\"\n",
    "python scripts/train_annual_2stage_preinit.py \\\n",
    "  --init_dir \"${CKPT_DIR}/${d}_${init_y}_seed\" \\\n",
    "  --node_vocab_txt ./tokenizer/concept_vocab_encoded.txt \\\n",
    "  --years 1991 \\\n",
    "  --dataset_template \"${DATASET_DIR}/${d}_{year}\" \\\n",
    "  --output_base_dir \"${CKPT_DIR}/${d}_annual\" \\\n",
    "  --exact_k_masks 1 \\\n",
    "  --num_train_epochs 2 \\\n",
    "  --learning_rate 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ce59483-7446-4714-a66c-1c201bd82dd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loaded node vocab: 22577\n",
      "[OK] saved ./outputs/start=uniform/mask_pred/dist=1/year=1991/target=automation.tsv\n",
      "[OK] saved ./outputs/start=uniform/mask_pred/dist=1/year=1991/target=productivity.tsv\n",
      "[OK] saved ./outputs/start=uniform/mask_pred/dist=1/year=1991/target=health_care.tsv\n",
      "[OK] saved ./outputs/start=uniform/mask_pred/dist=1/year=1991/target=legislation.tsv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /root/science-society\n",
    "\n",
    "START_MODE=\"uniform\"\n",
    "\n",
    "if [ \"${START_MODE}\" = \"per_node\" ]; then\n",
    "  MODE_TAG=\"start=${START_MODE}__scheme=${PER_NODE_SCHEME}\"\n",
    "else\n",
    "  MODE_TAG=\"start=${START_MODE}\"\n",
    "fi\n",
    "\n",
    "CORPUS_DIR=\"./corpus/${MODE_TAG}\"\n",
    "CKPT_DIR=\"./checkpoints/${MODE_TAG}\"\n",
    "OUT_DIR=\"./outputs/${MODE_TAG}\"\n",
    "mkdir -p \"${OUT_DIR}\"\n",
    "\n",
    "python scripts/predict_neighbors_by_distance.py \\\n",
    "  --years 1991 \\\n",
    "  --domains news paper \\\n",
    "  --ckpt_root \"${CKPT_DIR}\" \\\n",
    "  --corpus_root \"${CORPUS_DIR}\" \\\n",
    "  --node_vocab_txt ./tokenizer/concept_vocab_encoded.txt \\\n",
    "  --targets automation productivity health_care legislation \\\n",
    "  --distance 1 \\\n",
    "  --topk 30 \\\n",
    "  --max_contexts 1000 \\\n",
    "  --out_root \"${OUT_DIR}/mask_pred\" \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee9fc71f-db7c-4736-abee-7f9037d05f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== TARGET: automation ==============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>news_neighbor</th>\n",
       "      <th>news_avg_prob</th>\n",
       "      <th>paper_neighbor</th>\n",
       "      <th>paper_avg_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dining_rooms</td>\n",
       "      <td>0.389015</td>\n",
       "      <td>bidding</td>\n",
       "      <td>0.141014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>bureaucracy</td>\n",
       "      <td>0.248747</td>\n",
       "      <td>thematic_map</td>\n",
       "      <td>0.080273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>firearms</td>\n",
       "      <td>0.169783</td>\n",
       "      <td>attendance</td>\n",
       "      <td>0.062786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>golf</td>\n",
       "      <td>0.153054</td>\n",
       "      <td>drilling</td>\n",
       "      <td>0.060991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>puzzles</td>\n",
       "      <td>0.151183</td>\n",
       "      <td>nuclear_reactor</td>\n",
       "      <td>0.059015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>golf_courses</td>\n",
       "      <td>0.114111</td>\n",
       "      <td>buddhism</td>\n",
       "      <td>0.042640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>0.105563</td>\n",
       "      <td>traffic_congestion</td>\n",
       "      <td>0.040231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>influence</td>\n",
       "      <td>0.099648</td>\n",
       "      <td>hazard</td>\n",
       "      <td>0.039555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>appliances</td>\n",
       "      <td>0.098346</td>\n",
       "      <td>accreditation</td>\n",
       "      <td>0.039422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>deafness</td>\n",
       "      <td>0.093943</td>\n",
       "      <td>geometric_design</td>\n",
       "      <td>0.034473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>static_electricity</td>\n",
       "      <td>0.086111</td>\n",
       "      <td>tourism</td>\n",
       "      <td>0.033868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>child_care</td>\n",
       "      <td>0.080566</td>\n",
       "      <td>backup</td>\n",
       "      <td>0.032182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>agricultural_lending</td>\n",
       "      <td>0.077737</td>\n",
       "      <td>warning_system</td>\n",
       "      <td>0.030731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>accreditation</td>\n",
       "      <td>0.075215</td>\n",
       "      <td>stressor</td>\n",
       "      <td>0.030497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>corporate_bonds</td>\n",
       "      <td>0.072947</td>\n",
       "      <td>sewage</td>\n",
       "      <td>0.030489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>senators</td>\n",
       "      <td>0.071432</td>\n",
       "      <td>censorship</td>\n",
       "      <td>0.029180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>white_collar_workers</td>\n",
       "      <td>0.066541</td>\n",
       "      <td>internship</td>\n",
       "      <td>0.028228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>tires</td>\n",
       "      <td>0.062071</td>\n",
       "      <td>antigen</td>\n",
       "      <td>0.026822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>motion_picture_directors_&amp;_producers</td>\n",
       "      <td>0.060984</td>\n",
       "      <td>road_map</td>\n",
       "      <td>0.023747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>poultry</td>\n",
       "      <td>0.057739</td>\n",
       "      <td>energy_consumption</td>\n",
       "      <td>0.022520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank                         news_neighbor  news_avg_prob  \\\n",
       "0      1                          dining_rooms       0.389015   \n",
       "1      2                           bureaucracy       0.248747   \n",
       "2      3                              firearms       0.169783   \n",
       "3      4                                  golf       0.153054   \n",
       "4      5                               puzzles       0.151183   \n",
       "5      6                          golf_courses       0.114111   \n",
       "6      7                           mathematics       0.105563   \n",
       "7      8                             influence       0.099648   \n",
       "8      9                            appliances       0.098346   \n",
       "9     10                              deafness       0.093943   \n",
       "10    11                    static_electricity       0.086111   \n",
       "11    12                            child_care       0.080566   \n",
       "12    13                  agricultural_lending       0.077737   \n",
       "13    14                         accreditation       0.075215   \n",
       "14    15                       corporate_bonds       0.072947   \n",
       "15    16                              senators       0.071432   \n",
       "16    17                  white_collar_workers       0.066541   \n",
       "17    18                                 tires       0.062071   \n",
       "18    19  motion_picture_directors_&_producers       0.060984   \n",
       "19    20                               poultry       0.057739   \n",
       "\n",
       "        paper_neighbor  paper_avg_prob  \n",
       "0              bidding        0.141014  \n",
       "1         thematic_map        0.080273  \n",
       "2           attendance        0.062786  \n",
       "3             drilling        0.060991  \n",
       "4      nuclear_reactor        0.059015  \n",
       "5             buddhism        0.042640  \n",
       "6   traffic_congestion        0.040231  \n",
       "7               hazard        0.039555  \n",
       "8        accreditation        0.039422  \n",
       "9     geometric_design        0.034473  \n",
       "10             tourism        0.033868  \n",
       "11              backup        0.032182  \n",
       "12      warning_system        0.030731  \n",
       "13            stressor        0.030497  \n",
       "14              sewage        0.030489  \n",
       "15          censorship        0.029180  \n",
       "16          internship        0.028228  \n",
       "17             antigen        0.026822  \n",
       "18            road_map        0.023747  \n",
       "19  energy_consumption        0.022520  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== TARGET: productivity ==============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>news_neighbor</th>\n",
       "      <th>news_avg_prob</th>\n",
       "      <th>paper_neighbor</th>\n",
       "      <th>paper_avg_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>appropriations</td>\n",
       "      <td>0.491235</td>\n",
       "      <td>early_childhood</td>\n",
       "      <td>0.073032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>influence</td>\n",
       "      <td>0.127337</td>\n",
       "      <td>scalp</td>\n",
       "      <td>0.046143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>watches_and_clocks</td>\n",
       "      <td>0.092129</td>\n",
       "      <td>lease</td>\n",
       "      <td>0.042060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>vendors</td>\n",
       "      <td>0.086512</td>\n",
       "      <td>exhibition</td>\n",
       "      <td>0.041916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>cameras</td>\n",
       "      <td>0.069361</td>\n",
       "      <td>network_packet</td>\n",
       "      <td>0.041766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>natural_gas</td>\n",
       "      <td>0.063958</td>\n",
       "      <td>database_transaction</td>\n",
       "      <td>0.039842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>technology_transfer</td>\n",
       "      <td>0.058605</td>\n",
       "      <td>greenhouse</td>\n",
       "      <td>0.037109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>advertising_agencies</td>\n",
       "      <td>0.055034</td>\n",
       "      <td>active_listening</td>\n",
       "      <td>0.031579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>tolls</td>\n",
       "      <td>0.054505</td>\n",
       "      <td>air_pollution</td>\n",
       "      <td>0.031273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>conveyor_lines</td>\n",
       "      <td>0.052666</td>\n",
       "      <td>bearing_capacity</td>\n",
       "      <td>0.031188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>mars</td>\n",
       "      <td>0.051839</td>\n",
       "      <td>kannada</td>\n",
       "      <td>0.031139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>environmental_cleanup</td>\n",
       "      <td>0.049299</td>\n",
       "      <td>hue</td>\n",
       "      <td>0.031007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>senators</td>\n",
       "      <td>0.048875</td>\n",
       "      <td>recreation</td>\n",
       "      <td>0.028585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>salmonella</td>\n",
       "      <td>0.048242</td>\n",
       "      <td>doors</td>\n",
       "      <td>0.026512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>globalization</td>\n",
       "      <td>0.047627</td>\n",
       "      <td>amino_acid</td>\n",
       "      <td>0.025078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>biographies</td>\n",
       "      <td>0.046999</td>\n",
       "      <td>enzyme</td>\n",
       "      <td>0.023364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>contests</td>\n",
       "      <td>0.045887</td>\n",
       "      <td>early_childhood_education</td>\n",
       "      <td>0.022020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>explosives</td>\n",
       "      <td>0.043870</td>\n",
       "      <td>manufacturing_process</td>\n",
       "      <td>0.021047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>toll_roads</td>\n",
       "      <td>0.043833</td>\n",
       "      <td>capital_expenditure</td>\n",
       "      <td>0.019802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>company_reports</td>\n",
       "      <td>0.043710</td>\n",
       "      <td>intelligent_transportation_system</td>\n",
       "      <td>0.019266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank          news_neighbor  news_avg_prob  \\\n",
       "0      1         appropriations       0.491235   \n",
       "1      2              influence       0.127337   \n",
       "2      3     watches_and_clocks       0.092129   \n",
       "3      4                vendors       0.086512   \n",
       "4      5                cameras       0.069361   \n",
       "5      6            natural_gas       0.063958   \n",
       "6      7    technology_transfer       0.058605   \n",
       "7      8   advertising_agencies       0.055034   \n",
       "8      9                  tolls       0.054505   \n",
       "9     10         conveyor_lines       0.052666   \n",
       "10    11                   mars       0.051839   \n",
       "11    12  environmental_cleanup       0.049299   \n",
       "12    13               senators       0.048875   \n",
       "13    14             salmonella       0.048242   \n",
       "14    15          globalization       0.047627   \n",
       "15    16            biographies       0.046999   \n",
       "16    17               contests       0.045887   \n",
       "17    18             explosives       0.043870   \n",
       "18    19             toll_roads       0.043833   \n",
       "19    20        company_reports       0.043710   \n",
       "\n",
       "                       paper_neighbor  paper_avg_prob  \n",
       "0                     early_childhood        0.073032  \n",
       "1                               scalp        0.046143  \n",
       "2                               lease        0.042060  \n",
       "3                          exhibition        0.041916  \n",
       "4                      network_packet        0.041766  \n",
       "5                database_transaction        0.039842  \n",
       "6                          greenhouse        0.037109  \n",
       "7                    active_listening        0.031579  \n",
       "8                       air_pollution        0.031273  \n",
       "9                    bearing_capacity        0.031188  \n",
       "10                            kannada        0.031139  \n",
       "11                                hue        0.031007  \n",
       "12                         recreation        0.028585  \n",
       "13                              doors        0.026512  \n",
       "14                         amino_acid        0.025078  \n",
       "15                             enzyme        0.023364  \n",
       "16          early_childhood_education        0.022020  \n",
       "17              manufacturing_process        0.021047  \n",
       "18                capital_expenditure        0.019802  \n",
       "19  intelligent_transportation_system        0.019266  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== TARGET: health_care ==============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>news_neighbor</th>\n",
       "      <th>news_avg_prob</th>\n",
       "      <th>paper_neighbor</th>\n",
       "      <th>paper_avg_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>building_materials</td>\n",
       "      <td>0.279601</td>\n",
       "      <td>fishing</td>\n",
       "      <td>0.087897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>stock_exchanges</td>\n",
       "      <td>0.187968</td>\n",
       "      <td>palestine</td>\n",
       "      <td>0.069444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>acquisitions_&amp;_mergers</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>self</td>\n",
       "      <td>0.067070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>robots</td>\n",
       "      <td>0.081753</td>\n",
       "      <td>primate</td>\n",
       "      <td>0.053679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>parents_&amp;_parenting</td>\n",
       "      <td>0.069680</td>\n",
       "      <td>skepticism</td>\n",
       "      <td>0.052955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>stock_prices</td>\n",
       "      <td>0.065067</td>\n",
       "      <td>font</td>\n",
       "      <td>0.052327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>heart</td>\n",
       "      <td>0.060778</td>\n",
       "      <td>craft</td>\n",
       "      <td>0.047408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>spelling</td>\n",
       "      <td>0.059364</td>\n",
       "      <td>retail_banking</td>\n",
       "      <td>0.038284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>politics</td>\n",
       "      <td>0.056352</td>\n",
       "      <td>news_media</td>\n",
       "      <td>0.036774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>chemicals</td>\n",
       "      <td>0.055790</td>\n",
       "      <td>journalism</td>\n",
       "      <td>0.034827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>loans</td>\n",
       "      <td>0.054327</td>\n",
       "      <td>snow</td>\n",
       "      <td>0.034576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>apparel</td>\n",
       "      <td>0.049929</td>\n",
       "      <td>conversation</td>\n",
       "      <td>0.030548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>health_care</td>\n",
       "      <td>0.047434</td>\n",
       "      <td>mass_media</td>\n",
       "      <td>0.030290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>physicians</td>\n",
       "      <td>0.046475</td>\n",
       "      <td>global_positioning_system</td>\n",
       "      <td>0.030028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>missiles</td>\n",
       "      <td>0.045894</td>\n",
       "      <td>sewage_treatment</td>\n",
       "      <td>0.028790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>stock_brokers</td>\n",
       "      <td>0.039008</td>\n",
       "      <td>new_product_development</td>\n",
       "      <td>0.026649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>books</td>\n",
       "      <td>0.034828</td>\n",
       "      <td>early_childhood</td>\n",
       "      <td>0.026577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>securities_markets</td>\n",
       "      <td>0.034708</td>\n",
       "      <td>saint</td>\n",
       "      <td>0.026566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>composite_materials</td>\n",
       "      <td>0.034707</td>\n",
       "      <td>nuclear_power</td>\n",
       "      <td>0.025136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>futures_trading</td>\n",
       "      <td>0.034542</td>\n",
       "      <td>self-concept</td>\n",
       "      <td>0.024700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank           news_neighbor  news_avg_prob             paper_neighbor  \\\n",
       "0      1      building_materials       0.279601                    fishing   \n",
       "1      2         stock_exchanges       0.187968                  palestine   \n",
       "2      3  acquisitions_&_mergers       0.105882                       self   \n",
       "3      4                  robots       0.081753                    primate   \n",
       "4      5     parents_&_parenting       0.069680                 skepticism   \n",
       "5      6            stock_prices       0.065067                       font   \n",
       "6      7                   heart       0.060778                      craft   \n",
       "7      8                spelling       0.059364             retail_banking   \n",
       "8      9                politics       0.056352                 news_media   \n",
       "9     10               chemicals       0.055790                 journalism   \n",
       "10    11                   loans       0.054327                       snow   \n",
       "11    12                 apparel       0.049929               conversation   \n",
       "12    13             health_care       0.047434                 mass_media   \n",
       "13    14              physicians       0.046475  global_positioning_system   \n",
       "14    15                missiles       0.045894           sewage_treatment   \n",
       "15    16           stock_brokers       0.039008    new_product_development   \n",
       "16    17                   books       0.034828            early_childhood   \n",
       "17    18      securities_markets       0.034708                      saint   \n",
       "18    19     composite_materials       0.034707              nuclear_power   \n",
       "19    20         futures_trading       0.034542               self-concept   \n",
       "\n",
       "    paper_avg_prob  \n",
       "0         0.087897  \n",
       "1         0.069444  \n",
       "2         0.067070  \n",
       "3         0.053679  \n",
       "4         0.052955  \n",
       "5         0.052327  \n",
       "6         0.047408  \n",
       "7         0.038284  \n",
       "8         0.036774  \n",
       "9         0.034827  \n",
       "10        0.034576  \n",
       "11        0.030548  \n",
       "12        0.030290  \n",
       "13        0.030028  \n",
       "14        0.028790  \n",
       "15        0.026649  \n",
       "16        0.026577  \n",
       "17        0.026566  \n",
       "18        0.025136  \n",
       "19        0.024700  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== TARGET: legislation ==============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>news_neighbor</th>\n",
       "      <th>news_avg_prob</th>\n",
       "      <th>paper_neighbor</th>\n",
       "      <th>paper_avg_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mathematicians</td>\n",
       "      <td>0.299448</td>\n",
       "      <td>enlightenment</td>\n",
       "      <td>0.110821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>bids</td>\n",
       "      <td>0.264196</td>\n",
       "      <td>diesel_fuel</td>\n",
       "      <td>0.064273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>heart</td>\n",
       "      <td>0.148599</td>\n",
       "      <td>cracking</td>\n",
       "      <td>0.036990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>nuclear_weapons</td>\n",
       "      <td>0.138010</td>\n",
       "      <td>engineering_design_process</td>\n",
       "      <td>0.034086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>corrections</td>\n",
       "      <td>0.129359</td>\n",
       "      <td>petroleum</td>\n",
       "      <td>0.028044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>sensors</td>\n",
       "      <td>0.084653</td>\n",
       "      <td>national_security</td>\n",
       "      <td>0.027946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>treasury</td>\n",
       "      <td>0.078682</td>\n",
       "      <td>nuclear_power</td>\n",
       "      <td>0.027069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>tuition</td>\n",
       "      <td>0.076840</td>\n",
       "      <td>resource_allocation</td>\n",
       "      <td>0.026697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>treasury_notes</td>\n",
       "      <td>0.063426</td>\n",
       "      <td>documentation</td>\n",
       "      <td>0.023119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>weapons</td>\n",
       "      <td>0.057049</td>\n",
       "      <td>cancer</td>\n",
       "      <td>0.019358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>personality</td>\n",
       "      <td>0.054250</td>\n",
       "      <td>buddhism</td>\n",
       "      <td>0.019343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>0.054194</td>\n",
       "      <td>voltage</td>\n",
       "      <td>0.018803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>handicapped_accessibility</td>\n",
       "      <td>0.051181</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>0.017431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>resorts_&amp;_spas</td>\n",
       "      <td>0.050624</td>\n",
       "      <td>engineering_education</td>\n",
       "      <td>0.017422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>poultry</td>\n",
       "      <td>0.046740</td>\n",
       "      <td>socialization</td>\n",
       "      <td>0.017411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>military_weapons</td>\n",
       "      <td>0.046082</td>\n",
       "      <td>food_safety</td>\n",
       "      <td>0.017371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>violence</td>\n",
       "      <td>0.046070</td>\n",
       "      <td>systems_design</td>\n",
       "      <td>0.016629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>treasury_bonds</td>\n",
       "      <td>0.045687</td>\n",
       "      <td>nuclear_weapon</td>\n",
       "      <td>0.015976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>nuclear_energy</td>\n",
       "      <td>0.042506</td>\n",
       "      <td>treaty</td>\n",
       "      <td>0.015902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>informal_economy</td>\n",
       "      <td>0.042212</td>\n",
       "      <td>fuel_efficiency</td>\n",
       "      <td>0.015836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank              news_neighbor  news_avg_prob  \\\n",
       "0      1             mathematicians       0.299448   \n",
       "1      2                       bids       0.264196   \n",
       "2      3                      heart       0.148599   \n",
       "3      4            nuclear_weapons       0.138010   \n",
       "4      5                corrections       0.129359   \n",
       "5      6                    sensors       0.084653   \n",
       "6      7                   treasury       0.078682   \n",
       "7      8                    tuition       0.076840   \n",
       "8      9             treasury_notes       0.063426   \n",
       "9     10                    weapons       0.057049   \n",
       "10    11                personality       0.054250   \n",
       "11    12                mathematics       0.054194   \n",
       "12    13  handicapped_accessibility       0.051181   \n",
       "13    14             resorts_&_spas       0.050624   \n",
       "14    15                    poultry       0.046740   \n",
       "15    16           military_weapons       0.046082   \n",
       "16    17                   violence       0.046070   \n",
       "17    18             treasury_bonds       0.045687   \n",
       "18    19             nuclear_energy       0.042506   \n",
       "19    20           informal_economy       0.042212   \n",
       "\n",
       "                paper_neighbor  paper_avg_prob  \n",
       "0                enlightenment        0.110821  \n",
       "1                  diesel_fuel        0.064273  \n",
       "2                     cracking        0.036990  \n",
       "3   engineering_design_process        0.034086  \n",
       "4                    petroleum        0.028044  \n",
       "5            national_security        0.027946  \n",
       "6                nuclear_power        0.027069  \n",
       "7          resource_allocation        0.026697  \n",
       "8                documentation        0.023119  \n",
       "9                       cancer        0.019358  \n",
       "10                    buddhism        0.019343  \n",
       "11                     voltage        0.018803  \n",
       "12                    gasoline        0.017431  \n",
       "13       engineering_education        0.017422  \n",
       "14               socialization        0.017411  \n",
       "15                 food_safety        0.017371  \n",
       "16              systems_design        0.016629  \n",
       "17              nuclear_weapon        0.015976  \n",
       "18                      treaty        0.015902  \n",
       "19             fuel_efficiency        0.015836  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "\n",
    "targets = [\n",
    "    \"automation\", \"productivity\", \"health_care\", \"legislation\",\n",
    "]\n",
    "\n",
    "base = \"/root/science-society/outputs/start=uniform/mask_pred/dist=1/year=1991\"\n",
    "for t in targets:\n",
    "    path = f\"{base}/target={t}.tsv\"\n",
    "    print(f\"\\n============================== TARGET: {t} ==============================\")\n",
    "    df = pd.read_csv(path, sep=\"\\t\")\n",
    "    display(df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d18f07d-9833-4812-bf70-63ed483ddd95",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/root/science-society/scripts/check_conditional_from_corpus.py\", line 110, in <module>\n",
      "    main()\n",
      "  File \"/root/science-society/scripts/check_conditional_from_corpus.py\", line 63, in main\n",
      "    for li, toks in enumerate(iter_corpus(args.corpus)):\n",
      "  File \"/root/science-society/scripts/check_conditional_from_corpus.py\", line 7, in iter_corpus\n",
      "    with open(path, encoding=\"utf-8\") as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './corpus/news_1991.txt'\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/science-society/scripts/check_conditional_from_corpus.py\", line 110, in <module>\n",
      "    main()\n",
      "  File \"/root/science-society/scripts/check_conditional_from_corpus.py\", line 63, in main\n",
      "    for li, toks in enumerate(iter_corpus(args.corpus)):\n",
      "  File \"/root/science-society/scripts/check_conditional_from_corpus.py\", line 7, in iter_corpus\n",
      "    with open(path, encoding=\"utf-8\") as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './corpus/paper_1991.txt'\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'cd /root/science-society\\n\\npython scripts/check_conditional_from_corpus.py \\\\\\n  --corpus ./corpus/news_1991.txt \\\\\\n  --targets automation productivity health_care legislation \\\\\\n  --distance 1 \\\\\\n  --topk 30\\n\\npython scripts/check_conditional_from_corpus.py \\\\\\n  --corpus ./corpus/paper_1991.txt \\\\\\n  --targets automation productivity health_care legislation \\\\\\n  --distance 1 \\\\\\n  --topk 30\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcd /root/science-society\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mpython scripts/check_conditional_from_corpus.py \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  --corpus ./corpus/news_1991.txt \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  --targets automation productivity health_care legislation \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  --distance 1 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  --topk 30\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mpython scripts/check_conditional_from_corpus.py \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  --corpus ./corpus/paper_1991.txt \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  --targets automation productivity health_care legislation \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  --distance 1 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  --topk 30\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:2541\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2539\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2540\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2541\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2543\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2544\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2545\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magics/script.py:155\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magics/script.py:315\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'cd /root/science-society\\n\\npython scripts/check_conditional_from_corpus.py \\\\\\n  --corpus ./corpus/news_1991.txt \\\\\\n  --targets automation productivity health_care legislation \\\\\\n  --distance 1 \\\\\\n  --topk 30\\n\\npython scripts/check_conditional_from_corpus.py \\\\\\n  --corpus ./corpus/paper_1991.txt \\\\\\n  --targets automation productivity health_care legislation \\\\\\n  --distance 1 \\\\\\n  --topk 30\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /root/science-society\n",
    "\n",
    "python scripts/check_conditional_from_corpus.py \\\n",
    "  --corpus ./corpus/news_1991.txt \\\n",
    "  --targets automation productivity health_care legislation \\\n",
    "  --distance 1 \\\n",
    "  --topk 30\n",
    "\n",
    "python scripts/check_conditional_from_corpus.py \\\n",
    "  --corpus ./corpus/paper_1991.txt \\\n",
    "  --targets automation productivity health_care legislation \\\n",
    "  --distance 1 \\\n",
    "  --topk 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088850f1-1e4b-414b-89e4-f0e4698dd94a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
