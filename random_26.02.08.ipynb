{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dabadec-09da-4840-9eeb-f6741432b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"`tokenizer` is deprecated and will be removed in version 5.0.0\"\n",
    ")\n",
    "\n",
    "import transformers\n",
    "transformers.utils.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6537b2ec-c460-4ce3-b43f-ce9383a9a5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/news_1990.txt\n",
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/paper_1990.txt\n",
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/news_1991.txt\n",
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/paper_1991.txt\n",
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/news_1992.txt\n",
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/paper_1992.txt\n",
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/news_1993.txt\n",
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/paper_1993.txt\n",
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/news_1994.txt\n",
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/paper_1994.txt\n",
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/news_1995.txt\n",
      "[OK] start_mode=uniform wrote 20000 walks to ./corpus/start=uniform/paper_1995.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /root/science-society\n",
    "\n",
    "START_MODE=\"uniform\"\n",
    "\n",
    "if [ \"${START_MODE}\" = \"per_node\" ]; then\n",
    "  MODE_TAG=\"start=${START_MODE}__scheme=${PER_NODE_SCHEME}\"\n",
    "else\n",
    "  MODE_TAG=\"start=${START_MODE}\"\n",
    "fi\n",
    "\n",
    "CORPUS_DIR=\"./corpus/${MODE_TAG}\"\n",
    "MAP_DIR=\"./tokenizer/${MODE_TAG}\"\n",
    "mkdir -p \"${CORPUS_DIR}\" \"${MAP_DIR}\"\n",
    "\n",
    "for Y in 1990 1991 1992 1993 1994 1995; do\n",
    "  python ./scripts/make_walk_corpus_encoded.py \\\n",
    "    --pkl ./data/news/news_network_${Y}_m0.0-M1.0.pkl \\\n",
    "    --out \"${CORPUS_DIR}/news_${Y}.txt\" \\\n",
    "    --walk_length 20 --num_walks 20000 --seed 42 \\\n",
    "    --start_mode \"${START_MODE}\"\\\n",
    "    --mapping_json \"${MAP_DIR}/news_mapping_${Y}.json\"\n",
    "\n",
    "  python ./scripts/make_walk_corpus_encoded.py \\\n",
    "    --pkl ./data/paper/paper_network_${Y}_m0.0-M0.5.pkl \\\n",
    "    --out \"${CORPUS_DIR}/paper_${Y}.txt\" \\\n",
    "    --walk_length 20 --num_walks 20000 --seed 42 \\\n",
    "    --start_mode \"${START_MODE}\" \\\n",
    "    --mapping_json \"${MAP_DIR}/paper_mapping_${Y}.json\"\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb09fdaf-8ac6-4649-9198-a192689ec451",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1151759.23 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved news_1990 -> ./datasets/start=uniform/news_1990 (n=20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1516872.45 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved paper_1990 -> ./datasets/start=uniform/paper_1990 (n=20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1513833.94 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved news_1991 -> ./datasets/start=uniform/news_1991 (n=20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1525922.80 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved paper_1991 -> ./datasets/start=uniform/paper_1991 (n=20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1577873.75 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved news_1992 -> ./datasets/start=uniform/news_1992 (n=20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1523096.81 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved paper_1992 -> ./datasets/start=uniform/paper_1992 (n=20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1574467.99 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved news_1993 -> ./datasets/start=uniform/news_1993 (n=20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1497350.73 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved paper_1993 -> ./datasets/start=uniform/paper_1993 (n=20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1545261.76 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved news_1994 -> ./datasets/start=uniform/news_1994 (n=20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1484761.94 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved paper_1994 -> ./datasets/start=uniform/paper_1994 (n=20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1491944.65 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved news_1995 -> ./datasets/start=uniform/news_1995 (n=20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20000/20000 [00:00<00:00, 1519565.25 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved paper_1995 -> ./datasets/start=uniform/paper_1995 (n=20000)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /root/science-society\n",
    "\n",
    "START_MODE=\"uniform\"\n",
    "\n",
    "if [ \"${START_MODE}\" = \"per_node\" ]; then\n",
    "  MODE_TAG=\"start=${START_MODE}__scheme=${PER_NODE_SCHEME}\"\n",
    "else\n",
    "  MODE_TAG=\"start=${START_MODE}\"\n",
    "fi\n",
    "\n",
    "CORPUS_DIR=\"./corpus/${MODE_TAG}\"\n",
    "DATASET_DIR=\"./datasets/${MODE_TAG}\"\n",
    "mkdir -p \"${DATASET_DIR}\"\n",
    "\n",
    "python scripts/make_hf_dataset.py \\\n",
    "  --corpus_root \"${CORPUS_DIR}\" \\\n",
    "  --out_dir \"${DATASET_DIR}\" \\\n",
    "  --years 1990 1991 1992 1993 1994 1995 \\\n",
    "  --domains news paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fcd7665-f835-445e-b3cb-475ceca01b0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vocab] loaded node tokens: 22577\n",
      "[tokenizer] added tokens: 22577 (new vocab size=50345)\n",
      "[init] initialized added node token embeddings: 19823, fallback_to_UNK: 0\n",
      "[mask] node_token_ids in tokenizer: 22577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3095/3095 [03:09<00:00, 16.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.5141, 'grad_norm': 8.922683715820312, 'learning_rate': 4.975936748023376e-05, 'epoch': 0.32}\n",
      "{'loss': 6.3255, 'grad_norm': 7.7600884437561035, 'learning_rate': 4.6321760055001723e-05, 'epoch': 0.65}\n",
      "{'loss': 6.0977, 'grad_norm': 7.388082027435303, 'learning_rate': 4.288415262976968e-05, 'epoch': 0.97}\n",
      "{'loss': 5.9262, 'grad_norm': 7.509083271026611, 'learning_rate': 3.9446545204537646e-05, 'epoch': 1.29}\n",
      "{'loss': 5.7389, 'grad_norm': 9.221393585205078, 'learning_rate': 3.600893777930561e-05, 'epoch': 1.62}\n",
      "{'loss': 5.6237, 'grad_norm': 8.383805274963379, 'learning_rate': 3.257133035407357e-05, 'epoch': 1.94}\n",
      "{'loss': 5.4937, 'grad_norm': 9.7520751953125, 'learning_rate': 2.913372292884153e-05, 'epoch': 2.26}\n",
      "{'loss': 5.4093, 'grad_norm': 9.862661361694336, 'learning_rate': 2.569611550360949e-05, 'epoch': 2.58}\n",
      "{'loss': 5.3022, 'grad_norm': 8.153643608093262, 'learning_rate': 2.225850807837745e-05, 'epoch': 2.91}\n",
      "{'loss': 5.2436, 'grad_norm': 8.328288078308105, 'learning_rate': 1.8820900653145413e-05, 'epoch': 3.23}\n",
      "{'loss': 5.1512, 'grad_norm': 9.84145736694336, 'learning_rate': 1.5383293227913374e-05, 'epoch': 3.55}\n",
      "{'loss': 5.1133, 'grad_norm': 8.535040855407715, 'learning_rate': 1.1945685802681335e-05, 'epoch': 3.88}\n",
      "{'loss': 5.0546, 'grad_norm': 10.310990333557129, 'learning_rate': 8.508078377449295e-06, 'epoch': 4.2}\n",
      "{'loss': 5.0409, 'grad_norm': 11.539159774780273, 'learning_rate': 5.070470952217257e-06, 'epoch': 4.52}\n",
      "{'loss': 4.9906, 'grad_norm': 10.084176063537598, 'learning_rate': 1.6328635269852184e-06, 'epoch': 4.85}\n",
      "{'train_runtime': 189.1016, 'train_samples_per_second': 523.528, 'train_steps_per_second': 16.367, 'train_loss': 5.584071441305281, 'epoch': 5.0}\n",
      "[done] baseline saved to: ./checkpoints/start=uniform/news_1990_seed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vocab] loaded node tokens: 22577\n",
      "[tokenizer] added tokens: 22577 (new vocab size=50345)\n",
      "[init] initialized added node token embeddings: 19823, fallback_to_UNK: 0\n",
      "[mask] node_token_ids in tokenizer: 22577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3095/3095 [03:07<00:00, 16.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 8.6766, 'grad_norm': 10.301163673400879, 'learning_rate': 4.975936748023376e-05, 'epoch': 0.32}\n",
      "{'loss': 7.6179, 'grad_norm': 8.883499145507812, 'learning_rate': 4.6321760055001723e-05, 'epoch': 0.65}\n",
      "{'loss': 7.4292, 'grad_norm': 7.8002610206604, 'learning_rate': 4.288415262976968e-05, 'epoch': 0.97}\n",
      "{'loss': 7.2233, 'grad_norm': 8.817094802856445, 'learning_rate': 3.9446545204537646e-05, 'epoch': 1.29}\n",
      "{'loss': 7.1313, 'grad_norm': 8.841720581054688, 'learning_rate': 3.600893777930561e-05, 'epoch': 1.62}\n",
      "{'loss': 7.07, 'grad_norm': 7.936330318450928, 'learning_rate': 3.257133035407357e-05, 'epoch': 1.94}\n",
      "{'loss': 6.9678, 'grad_norm': 8.389918327331543, 'learning_rate': 2.913372292884153e-05, 'epoch': 2.26}\n",
      "{'loss': 6.9288, 'grad_norm': 8.752935409545898, 'learning_rate': 2.569611550360949e-05, 'epoch': 2.58}\n",
      "{'loss': 6.8726, 'grad_norm': 8.191651344299316, 'learning_rate': 2.225850807837745e-05, 'epoch': 2.91}\n",
      "{'loss': 6.8351, 'grad_norm': 9.218463897705078, 'learning_rate': 1.8820900653145413e-05, 'epoch': 3.23}\n",
      "{'loss': 6.7954, 'grad_norm': 9.118857383728027, 'learning_rate': 1.5383293227913374e-05, 'epoch': 3.55}\n",
      "{'loss': 6.7367, 'grad_norm': 8.504842758178711, 'learning_rate': 1.1945685802681335e-05, 'epoch': 3.88}\n",
      "{'loss': 6.7307, 'grad_norm': 10.128928184509277, 'learning_rate': 8.508078377449295e-06, 'epoch': 4.2}\n",
      "{'loss': 6.6926, 'grad_norm': 11.288307189941406, 'learning_rate': 5.070470952217257e-06, 'epoch': 4.52}\n",
      "{'loss': 6.6698, 'grad_norm': 9.363832473754883, 'learning_rate': 1.6328635269852184e-06, 'epoch': 4.85}\n",
      "{'train_runtime': 187.2207, 'train_samples_per_second': 528.788, 'train_steps_per_second': 16.531, 'train_loss': 7.080310847416448, 'epoch': 5.0}\n",
      "[done] baseline saved to: ./checkpoints/start=uniform/paper_1990_seed\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /root/science-society\n",
    "\n",
    "START_MODE=\"uniform\"\n",
    "\n",
    "if [ \"${START_MODE}\" = \"per_node\" ]; then\n",
    "  MODE_TAG=\"start=${START_MODE}__scheme=${PER_NODE_SCHEME}\"\n",
    "else\n",
    "  MODE_TAG=\"start=${START_MODE}\"\n",
    "fi\n",
    "\n",
    "y=1990\n",
    "DATASET_DIR=\"./datasets/${MODE_TAG}\"\n",
    "CKPT_DIR=\"./checkpoints/${MODE_TAG}\"\n",
    "mkdir -p \"${CKPT_DIR}\"\n",
    "\n",
    "python scripts/train_mlm_preinit.py \\\n",
    "  --dataset_dir \"${DATASET_DIR}/news_${y}\" \\\n",
    "  --node_vocab_txt ./tokenizer/concept_vocab_encoded.txt \\\n",
    "  --output_dir \"${CKPT_DIR}/news_${y}_seed\" \\\n",
    "  --num_train_epochs 5 \\\n",
    "  --learning_rate 5e-5 \\\n",
    "  --mlm_prob 0.15 \\\n",
    "  --mask_replace_prob 0.9 \\\n",
    "  --random_replace_prob 0.1\n",
    "\n",
    "python scripts/train_mlm_preinit.py \\\n",
    "  --dataset_dir \"${DATASET_DIR}/paper_${y}\" \\\n",
    "  --node_vocab_txt ./tokenizer/concept_vocab_encoded.txt \\\n",
    "  --output_dir \"${CKPT_DIR}/paper_${y}_seed\" \\\n",
    "  --num_train_epochs 5 \\\n",
    "  --learning_rate 5e-5 \\\n",
    "  --mlm_prob 0.15 \\\n",
    "  --mask_replace_prob 0.9 \\\n",
    "  --random_replace_prob 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "191fd6d7-3d45-4c5c-b92d-8d91a095855c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[plan]\n",
      "  - 1991: ./datasets/start=uniform/news_1991\n",
      "[vocab] node tokens: 22577\n",
      "\n",
      "==============================\n",
      "[year 1991] init_dir = ./checkpoints/start=uniform/news_1990_seed\n",
      "[year 1991] dataset_dir = ./datasets/start=uniform/news_1991\n",
      "[year 1991] node_token_ids in tokenizer: 22577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1238/1238 [01:17<00:00, 15.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.1425, 'grad_norm': 16.134113311767578, 'learning_rate': 8.92519346517627e-06, 'epoch': 0.32}\n",
      "{'loss': 6.5777, 'grad_norm': 18.4716796875, 'learning_rate': 7.2055030094582974e-06, 'epoch': 0.65}\n",
      "{'loss': 6.2562, 'grad_norm': 17.341468811035156, 'learning_rate': 5.485812553740327e-06, 'epoch': 0.97}\n",
      "{'loss': 6.1633, 'grad_norm': 16.555570602416992, 'learning_rate': 3.7661220980223563e-06, 'epoch': 1.29}\n",
      "{'loss': 5.9661, 'grad_norm': 17.260927200317383, 'learning_rate': 2.0464316423043853e-06, 'epoch': 1.62}\n",
      "{'loss': 5.9699, 'grad_norm': 19.834794998168945, 'learning_rate': 3.2674118658641445e-07, 'epoch': 1.94}\n",
      "{'train_runtime': 77.8009, 'train_samples_per_second': 508.992, 'train_steps_per_second': 15.912, 'train_loss': 6.334916837381045, 'epoch': 2.0}\n",
      "[year 1991] saved: ./checkpoints/start=uniform/news_annual/1991\n",
      "\n",
      "[done] all years finished.\n",
      "[done] final checkpoint: ./checkpoints/start=uniform/news_annual/1991\n",
      "[plan]\n",
      "  - 1991: ./datasets/start=uniform/paper_1991\n",
      "[vocab] node tokens: 22577\n",
      "\n",
      "==============================\n",
      "[year 1991] init_dir = ./checkpoints/start=uniform/paper_1990_seed\n",
      "[year 1991] dataset_dir = ./datasets/start=uniform/paper_1991\n",
      "[year 1991] node_token_ids in tokenizer: 22577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1238/1238 [01:18<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.7113, 'grad_norm': 14.740870475769043, 'learning_rate': 8.92519346517627e-06, 'epoch': 0.32}\n",
      "{'loss': 7.6502, 'grad_norm': 16.468698501586914, 'learning_rate': 7.2055030094582974e-06, 'epoch': 0.65}\n",
      "{'loss': 7.5727, 'grad_norm': 14.696656227111816, 'learning_rate': 5.485812553740327e-06, 'epoch': 0.97}\n",
      "{'loss': 7.5372, 'grad_norm': 14.171396255493164, 'learning_rate': 3.7661220980223563e-06, 'epoch': 1.29}\n",
      "{'loss': 7.5144, 'grad_norm': 16.50183868408203, 'learning_rate': 2.0464316423043853e-06, 'epoch': 1.62}\n",
      "{'loss': 7.5124, 'grad_norm': 15.455684661865234, 'learning_rate': 3.2674118658641445e-07, 'epoch': 1.94}\n",
      "{'train_runtime': 78.0063, 'train_samples_per_second': 507.651, 'train_steps_per_second': 15.871, 'train_loss': 7.578599871264136, 'epoch': 2.0}\n",
      "[year 1991] saved: ./checkpoints/start=uniform/paper_annual/1991\n",
      "\n",
      "[done] all years finished.\n",
      "[done] final checkpoint: ./checkpoints/start=uniform/paper_annual/1991\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /root/science-society\n",
    "\n",
    "START_MODE=\"uniform\"\n",
    "\n",
    "if [ \"${START_MODE}\" = \"per_node\" ]; then\n",
    "  MODE_TAG=\"start=${START_MODE}__scheme=${PER_NODE_SCHEME}\"\n",
    "else\n",
    "  MODE_TAG=\"start=${START_MODE}\"\n",
    "fi\n",
    "\n",
    "init_y=1990\n",
    "DATASET_DIR=\"./datasets/${MODE_TAG}\"\n",
    "CKPT_DIR=\"./checkpoints/${MODE_TAG}\"\n",
    "mkdir -p \"${CKPT_DIR}\"\n",
    "\n",
    "d=\"news\"\n",
    "python scripts/train_annual_2stage_preinit.py \\\n",
    "  --init_dir \"${CKPT_DIR}/${d}_${init_y}_seed\" \\\n",
    "  --node_vocab_txt ./tokenizer/concept_vocab_encoded.txt \\\n",
    "  --years 1991 1992 1993 1994 1995 \\\n",
    "  --dataset_template \"${DATASET_DIR}/${d}_{year}\" \\\n",
    "  --output_base_dir \"${CKPT_DIR}/${d}_annual\" \\\n",
    "  --exact_k_masks 1 \\\n",
    "  --num_train_epochs 2 \\\n",
    "  --learning_rate 1e-5 \\\n",
    "  --mask_replace_prob 0.8 \\\n",
    "  --random_replace_prob 0.1\n",
    "\n",
    "d=\"paper\"\n",
    "python scripts/train_annual_2stage_preinit.py \\\n",
    "  --init_dir \"${CKPT_DIR}/${d}_${init_y}_seed\" \\\n",
    "  --node_vocab_txt ./tokenizer/concept_vocab_encoded.txt \\\n",
    "  --years 1991 1992 1993 1994 1995 \\\n",
    "  --dataset_template \"${DATASET_DIR}/${d}_{year}\" \\\n",
    "  --output_base_dir \"${CKPT_DIR}/${d}_annual\" \\\n",
    "  --exact_k_masks 1 \\\n",
    "  --num_train_epochs 2 \\\n",
    "  --learning_rate 1e-5 \\\n",
    "  --mask_replace_prob 0.8 \\\n",
    "  --random_replace_prob 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ce59483-7446-4714-a66c-1c201bd82dd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loaded node vocab: 22577\n",
      "[OK] saved ./outputs/start=uniform/mask_pred/dist=1/year=1991/target=automation.tsv\n",
      "[OK] saved ./outputs/start=uniform/mask_pred/dist=1/year=1991/target=productivity.tsv\n",
      "[OK] saved ./outputs/start=uniform/mask_pred/dist=1/year=1991/target=health_care.tsv\n",
      "[OK] saved ./outputs/start=uniform/mask_pred/dist=1/year=1991/target=legislation.tsv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /root/science-society\n",
    "\n",
    "START_MODE=\"uniform\"\n",
    "\n",
    "if [ \"${START_MODE}\" = \"per_node\" ]; then\n",
    "  MODE_TAG=\"start=${START_MODE}__scheme=${PER_NODE_SCHEME}\"\n",
    "else\n",
    "  MODE_TAG=\"start=${START_MODE}\"\n",
    "fi\n",
    "\n",
    "CORPUS_DIR=\"./corpus/${MODE_TAG}\"\n",
    "CKPT_DIR=\"./checkpoints/${MODE_TAG}\"\n",
    "OUT_DIR=\"./outputs/${MODE_TAG}\"\n",
    "mkdir -p \"${OUT_DIR}\"\n",
    "\n",
    "python scripts/predict_neighbors_by_distance.py \\\n",
    "  --years 1991 \\\n",
    "  --domains news paper \\\n",
    "  --ckpt_root \"${CKPT_DIR}\" \\\n",
    "  --corpus_root \"${CORPUS_DIR}\" \\\n",
    "  --node_vocab_txt ./tokenizer/concept_vocab_encoded.txt \\\n",
    "  --targets automation productivity health_care legislation \\\n",
    "  --distance 1 \\\n",
    "  --topk 30 \\\n",
    "  --max_contexts 1000 \\\n",
    "  --out_root \"${OUT_DIR}/mask_pred\" \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee9fc71f-db7c-4736-abee-7f9037d05f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== TARGET: automation ==============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>news_neighbor</th>\n",
       "      <th>news_avg_prob</th>\n",
       "      <th>paper_neighbor</th>\n",
       "      <th>paper_avg_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dining_rooms</td>\n",
       "      <td>0.274881</td>\n",
       "      <td>bidding</td>\n",
       "      <td>0.083016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>firearms</td>\n",
       "      <td>0.177718</td>\n",
       "      <td>nuclear_reactor</td>\n",
       "      <td>0.065119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>appliances</td>\n",
       "      <td>0.146838</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>0.042574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>airlines_and_airplanes</td>\n",
       "      <td>0.123106</td>\n",
       "      <td>buddhism</td>\n",
       "      <td>0.033282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>bureaucracy</td>\n",
       "      <td>0.114293</td>\n",
       "      <td>traumatic_stress</td>\n",
       "      <td>0.033275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>golf</td>\n",
       "      <td>0.104868</td>\n",
       "      <td>rehabilitation</td>\n",
       "      <td>0.032782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>reconciliation</td>\n",
       "      <td>0.097166</td>\n",
       "      <td>drilling</td>\n",
       "      <td>0.028420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>poultry</td>\n",
       "      <td>0.088445</td>\n",
       "      <td>methane</td>\n",
       "      <td>0.027653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>organizational_behavior</td>\n",
       "      <td>0.061421</td>\n",
       "      <td>censorship</td>\n",
       "      <td>0.026326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>rubber</td>\n",
       "      <td>0.061180</td>\n",
       "      <td>antigen</td>\n",
       "      <td>0.025978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>0.058368</td>\n",
       "      <td>welfare</td>\n",
       "      <td>0.023598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>nutrition</td>\n",
       "      <td>0.058135</td>\n",
       "      <td>tourism</td>\n",
       "      <td>0.022101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>fire_stations</td>\n",
       "      <td>0.057925</td>\n",
       "      <td>nuclear_power</td>\n",
       "      <td>0.021265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>digital_computers</td>\n",
       "      <td>0.054415</td>\n",
       "      <td>hazard</td>\n",
       "      <td>0.021152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>globalization</td>\n",
       "      <td>0.052304</td>\n",
       "      <td>internship</td>\n",
       "      <td>0.020814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>senators</td>\n",
       "      <td>0.051456</td>\n",
       "      <td>elemental_analysis</td>\n",
       "      <td>0.020022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>tires</td>\n",
       "      <td>0.051070</td>\n",
       "      <td>vehicle_dynamics</td>\n",
       "      <td>0.019015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>golf_courses</td>\n",
       "      <td>0.048492</td>\n",
       "      <td>steering_wheel</td>\n",
       "      <td>0.018906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>lawn</td>\n",
       "      <td>0.047954</td>\n",
       "      <td>battle</td>\n",
       "      <td>0.018855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>maps</td>\n",
       "      <td>0.046197</td>\n",
       "      <td>hinduism</td>\n",
       "      <td>0.018663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank            news_neighbor  news_avg_prob      paper_neighbor  \\\n",
       "0      1             dining_rooms       0.274881             bidding   \n",
       "1      2                 firearms       0.177718     nuclear_reactor   \n",
       "2      3               appliances       0.146838            gasoline   \n",
       "3      4   airlines_and_airplanes       0.123106            buddhism   \n",
       "4      5              bureaucracy       0.114293    traumatic_stress   \n",
       "5      6                     golf       0.104868      rehabilitation   \n",
       "6      7           reconciliation       0.097166            drilling   \n",
       "7      8                  poultry       0.088445             methane   \n",
       "8      9  organizational_behavior       0.061421          censorship   \n",
       "9     10                   rubber       0.061180             antigen   \n",
       "10    11              mathematics       0.058368             welfare   \n",
       "11    12                nutrition       0.058135             tourism   \n",
       "12    13            fire_stations       0.057925       nuclear_power   \n",
       "13    14        digital_computers       0.054415              hazard   \n",
       "14    15            globalization       0.052304          internship   \n",
       "15    16                 senators       0.051456  elemental_analysis   \n",
       "16    17                    tires       0.051070    vehicle_dynamics   \n",
       "17    18             golf_courses       0.048492      steering_wheel   \n",
       "18    19                     lawn       0.047954              battle   \n",
       "19    20                     maps       0.046197            hinduism   \n",
       "\n",
       "    paper_avg_prob  \n",
       "0         0.083016  \n",
       "1         0.065119  \n",
       "2         0.042574  \n",
       "3         0.033282  \n",
       "4         0.033275  \n",
       "5         0.032782  \n",
       "6         0.028420  \n",
       "7         0.027653  \n",
       "8         0.026326  \n",
       "9         0.025978  \n",
       "10        0.023598  \n",
       "11        0.022101  \n",
       "12        0.021265  \n",
       "13        0.021152  \n",
       "14        0.020814  \n",
       "15        0.020022  \n",
       "16        0.019015  \n",
       "17        0.018906  \n",
       "18        0.018855  \n",
       "19        0.018663  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== TARGET: productivity ==============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>news_neighbor</th>\n",
       "      <th>news_avg_prob</th>\n",
       "      <th>paper_neighbor</th>\n",
       "      <th>paper_avg_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>appropriations</td>\n",
       "      <td>0.287721</td>\n",
       "      <td>kannada</td>\n",
       "      <td>0.070551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>senators</td>\n",
       "      <td>0.102447</td>\n",
       "      <td>lease</td>\n",
       "      <td>0.039882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>influence</td>\n",
       "      <td>0.080878</td>\n",
       "      <td>peat</td>\n",
       "      <td>0.036954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>petitions</td>\n",
       "      <td>0.070119</td>\n",
       "      <td>telugu</td>\n",
       "      <td>0.034580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>environmental_cleanup</td>\n",
       "      <td>0.069194</td>\n",
       "      <td>doors</td>\n",
       "      <td>0.033539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>mars</td>\n",
       "      <td>0.065319</td>\n",
       "      <td>collar</td>\n",
       "      <td>0.033268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>planets</td>\n",
       "      <td>0.059461</td>\n",
       "      <td>bengali</td>\n",
       "      <td>0.030059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>globalization</td>\n",
       "      <td>0.055566</td>\n",
       "      <td>database_transaction</td>\n",
       "      <td>0.029016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>watches_and_clocks</td>\n",
       "      <td>0.054370</td>\n",
       "      <td>exhibition</td>\n",
       "      <td>0.028796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>salmonella</td>\n",
       "      <td>0.052094</td>\n",
       "      <td>corrosion</td>\n",
       "      <td>0.027157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>theft</td>\n",
       "      <td>0.051285</td>\n",
       "      <td>interpersonal_communication</td>\n",
       "      <td>0.022131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>electronic_information_systems</td>\n",
       "      <td>0.048807</td>\n",
       "      <td>computational_complexity_theory</td>\n",
       "      <td>0.021955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>moon</td>\n",
       "      <td>0.046412</td>\n",
       "      <td>narrative</td>\n",
       "      <td>0.020888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>poultry</td>\n",
       "      <td>0.046015</td>\n",
       "      <td>scalp</td>\n",
       "      <td>0.020376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>pluto</td>\n",
       "      <td>0.041442</td>\n",
       "      <td>hue</td>\n",
       "      <td>0.020298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>geographic_information_systems</td>\n",
       "      <td>0.040497</td>\n",
       "      <td>hazard</td>\n",
       "      <td>0.019727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>biotechnology</td>\n",
       "      <td>0.040145</td>\n",
       "      <td>pollution</td>\n",
       "      <td>0.019722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>liability</td>\n",
       "      <td>0.039530</td>\n",
       "      <td>sugar</td>\n",
       "      <td>0.019524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>bacteria</td>\n",
       "      <td>0.038560</td>\n",
       "      <td>shipbuilding</td>\n",
       "      <td>0.019519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>biographies</td>\n",
       "      <td>0.038244</td>\n",
       "      <td>genus</td>\n",
       "      <td>0.018843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank                   news_neighbor  news_avg_prob  \\\n",
       "0      1                  appropriations       0.287721   \n",
       "1      2                        senators       0.102447   \n",
       "2      3                       influence       0.080878   \n",
       "3      4                       petitions       0.070119   \n",
       "4      5           environmental_cleanup       0.069194   \n",
       "5      6                            mars       0.065319   \n",
       "6      7                         planets       0.059461   \n",
       "7      8                   globalization       0.055566   \n",
       "8      9              watches_and_clocks       0.054370   \n",
       "9     10                      salmonella       0.052094   \n",
       "10    11                           theft       0.051285   \n",
       "11    12  electronic_information_systems       0.048807   \n",
       "12    13                            moon       0.046412   \n",
       "13    14                         poultry       0.046015   \n",
       "14    15                           pluto       0.041442   \n",
       "15    16  geographic_information_systems       0.040497   \n",
       "16    17                   biotechnology       0.040145   \n",
       "17    18                       liability       0.039530   \n",
       "18    19                        bacteria       0.038560   \n",
       "19    20                     biographies       0.038244   \n",
       "\n",
       "                     paper_neighbor  paper_avg_prob  \n",
       "0                           kannada        0.070551  \n",
       "1                             lease        0.039882  \n",
       "2                              peat        0.036954  \n",
       "3                            telugu        0.034580  \n",
       "4                             doors        0.033539  \n",
       "5                            collar        0.033268  \n",
       "6                           bengali        0.030059  \n",
       "7              database_transaction        0.029016  \n",
       "8                        exhibition        0.028796  \n",
       "9                         corrosion        0.027157  \n",
       "10      interpersonal_communication        0.022131  \n",
       "11  computational_complexity_theory        0.021955  \n",
       "12                        narrative        0.020888  \n",
       "13                            scalp        0.020376  \n",
       "14                              hue        0.020298  \n",
       "15                           hazard        0.019727  \n",
       "16                        pollution        0.019722  \n",
       "17                            sugar        0.019524  \n",
       "18                     shipbuilding        0.019519  \n",
       "19                            genus        0.018843  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== TARGET: health_care ==============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>news_neighbor</th>\n",
       "      <th>news_avg_prob</th>\n",
       "      <th>paper_neighbor</th>\n",
       "      <th>paper_avg_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>spelling</td>\n",
       "      <td>0.277930</td>\n",
       "      <td>saint</td>\n",
       "      <td>0.139366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>acquisitions_&amp;_mergers</td>\n",
       "      <td>0.214094</td>\n",
       "      <td>craft</td>\n",
       "      <td>0.109672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>stock_exchanges</td>\n",
       "      <td>0.172921</td>\n",
       "      <td>fishing</td>\n",
       "      <td>0.063341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>robots</td>\n",
       "      <td>0.073005</td>\n",
       "      <td>occupational_exposure</td>\n",
       "      <td>0.049460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>data_processing_(computers)</td>\n",
       "      <td>0.066685</td>\n",
       "      <td>teamwork</td>\n",
       "      <td>0.049407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>stock_prices</td>\n",
       "      <td>0.061635</td>\n",
       "      <td>retail_banking</td>\n",
       "      <td>0.049220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>legislatures</td>\n",
       "      <td>0.061521</td>\n",
       "      <td>early_childhood</td>\n",
       "      <td>0.041809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>health_care</td>\n",
       "      <td>0.054959</td>\n",
       "      <td>primate</td>\n",
       "      <td>0.039752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>politics</td>\n",
       "      <td>0.052042</td>\n",
       "      <td>self</td>\n",
       "      <td>0.029486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>heart</td>\n",
       "      <td>0.051772</td>\n",
       "      <td>early_childhood_education</td>\n",
       "      <td>0.028903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>cartography</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>aluminium</td>\n",
       "      <td>0.026778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>state_elections</td>\n",
       "      <td>0.040180</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>0.026334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>0.038486</td>\n",
       "      <td>mass_media</td>\n",
       "      <td>0.026285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>loans</td>\n",
       "      <td>0.034798</td>\n",
       "      <td>palestine</td>\n",
       "      <td>0.021849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>psychology</td>\n",
       "      <td>0.032095</td>\n",
       "      <td>global_positioning_system</td>\n",
       "      <td>0.021700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>net_losses</td>\n",
       "      <td>0.030652</td>\n",
       "      <td>islam</td>\n",
       "      <td>0.021299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>geographic_information_systems</td>\n",
       "      <td>0.030010</td>\n",
       "      <td>font</td>\n",
       "      <td>0.020671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>creativity</td>\n",
       "      <td>0.028889</td>\n",
       "      <td>journalism</td>\n",
       "      <td>0.019979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>committees</td>\n",
       "      <td>0.028271</td>\n",
       "      <td>action_plan</td>\n",
       "      <td>0.019697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>chemicals</td>\n",
       "      <td>0.027858</td>\n",
       "      <td>skepticism</td>\n",
       "      <td>0.019351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank                   news_neighbor  news_avg_prob  \\\n",
       "0      1                        spelling       0.277930   \n",
       "1      2          acquisitions_&_mergers       0.214094   \n",
       "2      3                 stock_exchanges       0.172921   \n",
       "3      4                          robots       0.073005   \n",
       "4      5     data_processing_(computers)       0.066685   \n",
       "5      6                    stock_prices       0.061635   \n",
       "6      7                    legislatures       0.061521   \n",
       "7      8                     health_care       0.054959   \n",
       "8      9                        politics       0.052042   \n",
       "9     10                           heart       0.051772   \n",
       "10    11                     cartography       0.043875   \n",
       "11    12                 state_elections       0.040180   \n",
       "12    13                      philosophy       0.038486   \n",
       "13    14                           loans       0.034798   \n",
       "14    15                      psychology       0.032095   \n",
       "15    16                      net_losses       0.030652   \n",
       "16    17  geographic_information_systems       0.030010   \n",
       "17    18                      creativity       0.028889   \n",
       "18    19                      committees       0.028271   \n",
       "19    20                       chemicals       0.027858   \n",
       "\n",
       "               paper_neighbor  paper_avg_prob  \n",
       "0                       saint        0.139366  \n",
       "1                       craft        0.109672  \n",
       "2                     fishing        0.063341  \n",
       "3       occupational_exposure        0.049460  \n",
       "4                    teamwork        0.049407  \n",
       "5              retail_banking        0.049220  \n",
       "6             early_childhood        0.041809  \n",
       "7                     primate        0.039752  \n",
       "8                        self        0.029486  \n",
       "9   early_childhood_education        0.028903  \n",
       "10                  aluminium        0.026778  \n",
       "11                  newspaper        0.026334  \n",
       "12                 mass_media        0.026285  \n",
       "13                  palestine        0.021849  \n",
       "14  global_positioning_system        0.021700  \n",
       "15                      islam        0.021299  \n",
       "16                       font        0.020671  \n",
       "17                 journalism        0.019979  \n",
       "18                action_plan        0.019697  \n",
       "19                 skepticism        0.019351  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== TARGET: legislation ==============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>news_neighbor</th>\n",
       "      <th>news_avg_prob</th>\n",
       "      <th>paper_neighbor</th>\n",
       "      <th>paper_avg_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mathematicians</td>\n",
       "      <td>0.357890</td>\n",
       "      <td>cracking</td>\n",
       "      <td>0.096354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>nuclear_weapons</td>\n",
       "      <td>0.218887</td>\n",
       "      <td>enlightenment</td>\n",
       "      <td>0.095019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>treasury_notes</td>\n",
       "      <td>0.100481</td>\n",
       "      <td>cancer</td>\n",
       "      <td>0.063249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sensors</td>\n",
       "      <td>0.079233</td>\n",
       "      <td>diesel_fuel</td>\n",
       "      <td>0.061703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>bids</td>\n",
       "      <td>0.070528</td>\n",
       "      <td>swallowing</td>\n",
       "      <td>0.051184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>treasury_bonds</td>\n",
       "      <td>0.068850</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>0.049381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>poultry</td>\n",
       "      <td>0.068645</td>\n",
       "      <td>petroleum</td>\n",
       "      <td>0.035806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>recycling</td>\n",
       "      <td>0.063552</td>\n",
       "      <td>recession</td>\n",
       "      <td>0.033730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>0.063363</td>\n",
       "      <td>nuclear_power</td>\n",
       "      <td>0.027603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>personality</td>\n",
       "      <td>0.057247</td>\n",
       "      <td>resource_allocation</td>\n",
       "      <td>0.027365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>informal_economy</td>\n",
       "      <td>0.054811</td>\n",
       "      <td>medical_record</td>\n",
       "      <td>0.026218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>nuclear_energy</td>\n",
       "      <td>0.053383</td>\n",
       "      <td>drama</td>\n",
       "      <td>0.026156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>legislation</td>\n",
       "      <td>0.045813</td>\n",
       "      <td>contrast_(vision)</td>\n",
       "      <td>0.021099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>weapons</td>\n",
       "      <td>0.044213</td>\n",
       "      <td>architecture</td>\n",
       "      <td>0.019628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>recycling_of_waste_materials</td>\n",
       "      <td>0.041762</td>\n",
       "      <td>engineering_design_process</td>\n",
       "      <td>0.019377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>resorts_&amp;_spas</td>\n",
       "      <td>0.040748</td>\n",
       "      <td>medical_imaging</td>\n",
       "      <td>0.019342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>securities_markets</td>\n",
       "      <td>0.040717</td>\n",
       "      <td>doctrine</td>\n",
       "      <td>0.019068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>sheep</td>\n",
       "      <td>0.039114</td>\n",
       "      <td>spanish_civil_war</td>\n",
       "      <td>0.018744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>handicapped</td>\n",
       "      <td>0.032362</td>\n",
       "      <td>security_policy</td>\n",
       "      <td>0.017659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>safety_standards</td>\n",
       "      <td>0.017453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank                 news_neighbor  news_avg_prob  \\\n",
       "0      1                mathematicians       0.357890   \n",
       "1      2               nuclear_weapons       0.218887   \n",
       "2      3                treasury_notes       0.100481   \n",
       "3      4                       sensors       0.079233   \n",
       "4      5                          bids       0.070528   \n",
       "5      6                treasury_bonds       0.068850   \n",
       "6      7                       poultry       0.068645   \n",
       "7      8                     recycling       0.063552   \n",
       "8      9                   mathematics       0.063363   \n",
       "9     10                   personality       0.057247   \n",
       "10    11              informal_economy       0.054811   \n",
       "11    12                nuclear_energy       0.053383   \n",
       "12    13                   legislation       0.045813   \n",
       "13    14                       weapons       0.044213   \n",
       "14    15  recycling_of_waste_materials       0.041762   \n",
       "15    16                resorts_&_spas       0.040748   \n",
       "16    17            securities_markets       0.040717   \n",
       "17    18                         sheep       0.039114   \n",
       "18    19                   handicapped       0.032362   \n",
       "19    20                    conspiracy       0.031284   \n",
       "\n",
       "                paper_neighbor  paper_avg_prob  \n",
       "0                     cracking        0.096354  \n",
       "1                enlightenment        0.095019  \n",
       "2                       cancer        0.063249  \n",
       "3                  diesel_fuel        0.061703  \n",
       "4                   swallowing        0.051184  \n",
       "5                     gasoline        0.049381  \n",
       "6                    petroleum        0.035806  \n",
       "7                    recession        0.033730  \n",
       "8                nuclear_power        0.027603  \n",
       "9          resource_allocation        0.027365  \n",
       "10              medical_record        0.026218  \n",
       "11                       drama        0.026156  \n",
       "12           contrast_(vision)        0.021099  \n",
       "13                architecture        0.019628  \n",
       "14  engineering_design_process        0.019377  \n",
       "15             medical_imaging        0.019342  \n",
       "16                    doctrine        0.019068  \n",
       "17           spanish_civil_war        0.018744  \n",
       "18             security_policy        0.017659  \n",
       "19            safety_standards        0.017453  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "\n",
    "targets = [\n",
    "    \"automation\", \"productivity\", \"health_care\", \"legislation\",\n",
    "]\n",
    "\n",
    "base = \"/root/science-society/outputs/start=uniform/mask_pred/dist=1/year=1991\"\n",
    "for t in targets:\n",
    "    path = f\"{base}/target={t}.tsv\"\n",
    "    print(f\"\\n============================== TARGET: {t} ==============================\")\n",
    "    df = pd.read_csv(path, sep=\"\\t\")\n",
    "    display(df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d18f07d-9833-4812-bf70-63ed483ddd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== TARGET: automation ==============================\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/root/science-society/outputs/start=uniform/mask_pred/dist=1/year=1994/target=automation.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/target=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m============================== TARGET: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ==============================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m display(df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m20\u001b[39m))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/science-society/outputs/start=uniform/mask_pred/dist=1/year=1994/target=automation.tsv'"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "\n",
    "targets = [\n",
    "    \"automation\", \"productivity\", \"health_care\", \"legislation\",\n",
    "]\n",
    "\n",
    "base = \"/root/science-society/outputs/start=uniform/mask_pred/dist=1/year=1994\"\n",
    "for t in targets:\n",
    "    path = f\"{base}/target={t}.tsv\"\n",
    "    print(f\"\\n============================== TARGET: {t} ==============================\")\n",
    "    df = pd.read_csv(path, sep=\"\\t\")\n",
    "    display(df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088850f1-1e4b-414b-89e4-f0e4698dd94a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
