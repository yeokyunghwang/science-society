{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8f94e29-87c5-4c02-b5c7-cd0c27981576",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81a62e90-ba95-46f8-bc99-ee3d3c7c2eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.makedirs(\"./data/news\", exist_ok=True)\n",
    "# os.makedirs(\"./data/paper\", exist_ok=True)\n",
    "# os.makedirs(\"./corpus\", exist_ok=True)\n",
    "# os.makedirs(\"./tokenizer/\", exist_ok=True)\n",
    "# os.makedirs(\"./checkpoints/\", exist_ok=True)\n",
    "# os.makedirs(\"./outputs/\", exist_ok=True)\n",
    "# os.makedirs(\"./scripts\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5891d585-21a5-49db-8b80-66d4d37e7403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade pip\n",
    "# pip uninstall numpy\n",
    "# pip install numpy\n",
    "# pip install --upgrade numpy\n",
    "# pip install transformers datasets tokenizers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6905228e-9b82-4b65-8595-b1669c81d62d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3792269792.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install datasets\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# %%bash\n",
    "# pip install -U \"numpy==1.26.4\" \"pandas==2.2.2\"\n",
    "# python - <<'PY'\n",
    "# import numpy as np, pandas as pd\n",
    "# print(\"numpy\", np.__version__)\n",
    "# print(\"pandas\", pd.__version__)\n",
    "# PY\n",
    "# pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf7717f-0e5f-469f-ac54-eee150c17a1d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e299122d-d329-4cd1-93d2-d7cb0c60dbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news nodes: 2434\n",
      "paper nodes: 12593\n",
      "common nodes: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# load news graph\n",
    "with open(\"./data/news/news_network_1990_m0.0-M1.0.pkl\", \"rb\") as f:\n",
    "    news_obj = pickle.load(f)\n",
    "news_nodes = set(news_obj[\"G\"].nodes())\n",
    "\n",
    "# load paper graph\n",
    "with open(\"./data/paper/paper_network_1990_m0.0-M0.5.pkl\", \"rb\") as f:\n",
    "    paper_obj = pickle.load(f)\n",
    "paper_nodes = set(paper_obj[\"G\"].nodes())\n",
    "\n",
    "# intersection\n",
    "common_nodes = news_nodes & paper_nodes\n",
    "\n",
    "print(\"news nodes:\", len(news_nodes))\n",
    "print(\"paper nodes:\", len(paper_nodes))\n",
    "print(\"common nodes:\", len(common_nodes))\n",
    "\n",
    "# 몇 개 샘플\n",
    "list(common_nodes)[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c875b020-0e12-4edf-afaa-cfd134107c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> dict_keys(['G'])\n",
      "nodes: 2434 edges: 43851\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pkl_path = \"./data/news/news_network_1990_m0.0-M1.0.pkl\"\n",
    "obj = pd.read_pickle(pkl_path)\n",
    "\n",
    "print(type(obj), obj.keys())\n",
    "G = obj[\"G\"]\n",
    "print(\"nodes:\", len(G.nodes()), \"edges:\", len(G.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05681139-5176-435b-bd25-c3ccbe5f98db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> dict_keys(['G'])\n",
      "nodes: 12593 edges: 397239\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pkl_path = \"./data/paper/paper_network_1990_m0.0-M0.5.pkl\"\n",
    "obj = pd.read_pickle(pkl_path)\n",
    "\n",
    "print(type(obj), obj.keys())\n",
    "G = obj[\"G\"]\n",
    "print(\"nodes:\", len(G.nodes()), \"edges:\", len(G.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c313a7cf-cb66-4dff-99d2-ec8d8455cefb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ebff2a5-88b3-4fac-a4ee-c30443bbbd95",
   "metadata": {},
   "source": [
    "## Code Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa459f8c-ca3a-4aad-aa3c-35c6d1fcce75",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Build vocab & tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1c9372a-df2a-412b-aa37-2f1acf8d5405",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python ./scripts/build_vocab.py \\\n",
    "  --data_root ./data \\\n",
    "  --years 1990 1991 1992 1993 1994 1995 \\\n",
    "  --out_vocab ./tokenizer/concept_vocab_encoded.txt \\\n",
    "  --out_mapping ./tokenizer/node_mapping.json \\\n",
    "  --out_common_dir ./outputs/common_node_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b6e9a15-2f07-4bb8-9fca-b1a5b696d8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] tokenizer.json saved_to=./tokenizer/tokenizer.json\n",
      "[OK] vocab_size=22582 (incl specials=5)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python scripts/build_tokenizer.py \\\n",
    "  --vocab_txt ./tokenizer/concept_vocab_encoded.txt \\\n",
    "  --out_dir ./tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f3dfae-712e-4591-866a-334977741af8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Make walk corpus & fit to HuggingFace dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08aecf79-3c23-4c35-9981-e61c9fbcdb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] start_mode=uniform wrote 10000 walks to ./corpus/news_1990.txt\n",
      "[OK] start_mode=uniform wrote 10000 walks to ./corpus/paper_1990.txt\n",
      "[OK] start_mode=uniform wrote 10000 walks to ./corpus/news_1991.txt\n",
      "[OK] start_mode=uniform wrote 10000 walks to ./corpus/paper_1991.txt\n",
      "[OK] start_mode=uniform wrote 10000 walks to ./corpus/news_1992.txt\n",
      "[OK] start_mode=uniform wrote 10000 walks to ./corpus/paper_1992.txt\n",
      "[OK] start_mode=uniform wrote 10000 walks to ./corpus/news_1993.txt\n",
      "[OK] start_mode=uniform wrote 10000 walks to ./corpus/paper_1993.txt\n",
      "[OK] start_mode=uniform wrote 10000 walks to ./corpus/news_1994.txt\n",
      "[OK] start_mode=uniform wrote 10000 walks to ./corpus/paper_1994.txt\n",
      "[OK] start_mode=uniform wrote 10000 walks to ./corpus/news_1995.txt\n",
      "[OK] start_mode=uniform wrote 10000 walks to ./corpus/paper_1995.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "for Y in 1990 1991 1992 1993 1994 1995; do\n",
    "  python scripts/make_walk_corpus_encoded.py \\\n",
    "    --pkl ./data/news/news_network_${Y}_m0.0-M1.0.pkl \\\n",
    "    --out ./corpus/news_${Y}.txt \\\n",
    "    --walk_length 20 --num_walks 10000 --seed 42 \\\n",
    "    --start_mode uniform \\\n",
    "    --mapping_json ./tokenizer/news_mapping_${Y}.json\n",
    "\n",
    "  python scripts/make_walk_corpus_encoded.py \\\n",
    "    --pkl ./data/paper/paper_network_${Y}_m0.0-M0.5.pkl \\\n",
    "    --out ./corpus/paper_${Y}.txt \\\n",
    "    --walk_length 20 --num_walks 10000 --seed 42 \\\n",
    "    --start_mode uniform \\\n",
    "    --mapping_json ./tokenizer/paper_mapping_${Y}.json\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc9a6d96-2f5c-422f-9e01-a37bd62be324",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 10000/10000 [00:00<00:00, 739670.93 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved news_1990 -> ./datasets/news_1990 (n=10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 10000/10000 [00:00<00:00, 988849.49 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved paper_1990 -> ./datasets/paper_1990 (n=10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 10000/10000 [00:00<00:00, 904919.96 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved news_1991 -> ./datasets/news_1991 (n=10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 10000/10000 [00:00<00:00, 1038065.59 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved paper_1991 -> ./datasets/paper_1991 (n=10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 10000/10000 [00:00<00:00, 973020.93 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved news_1992 -> ./datasets/news_1992 (n=10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 10000/10000 [00:00<00:00, 1086635.41 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved paper_1992 -> ./datasets/paper_1992 (n=10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 10000/10000 [00:00<00:00, 794721.94 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved news_1993 -> ./datasets/news_1993 (n=10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 10000/10000 [00:00<00:00, 845659.91 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved paper_1993 -> ./datasets/paper_1993 (n=10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 10000/10000 [00:00<00:00, 768243.83 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved news_1994 -> ./datasets/news_1994 (n=10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 10000/10000 [00:00<00:00, 1005611.26 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved paper_1994 -> ./datasets/paper_1994 (n=10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 10000/10000 [00:00<00:00, 1051230.36 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved news_1995 -> ./datasets/news_1995 (n=10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 10000/10000 [00:00<00:00, 864074.49 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved paper_1995 -> ./datasets/paper_1995 (n=10000)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python scripts/make_hf_dataset.py \\\n",
    "  --corpus_root ./corpus \\\n",
    "  --out_dir ./datasets \\\n",
    "  --years 1990 1991 1992 1993 1994 1995 \\\n",
    "  --domains news paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dabd98d-4fee-4da5-b543-c59dd4a6a99d",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eaf0f98-8e07-43d5-8a7b-3d9fa43ae860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 16541.62 examples/s]\n",
      "/root/scripts/train_mlm_stage1.py:83: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "100%|██████████| 313/313 [00:11<00:00, 26.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.5897, 'grad_norm': 1.7167348861694336, 'learning_rate': 0.00034185303514377, 'epoch': 0.32}\n",
      "{'loss': 5.7171, 'grad_norm': 1.7580832242965698, 'learning_rate': 0.00018210862619808308, 'epoch': 0.64}\n",
      "{'loss': 5.6739, 'grad_norm': 1.6948777437210083, 'learning_rate': 2.2364217252396165e-05, 'epoch': 0.96}\n",
      "{'train_runtime': 11.9363, 'train_samples_per_second': 837.778, 'train_steps_per_second': 26.222, 'train_loss': 5.978816510770268, 'epoch': 1.0}\n",
      "[OK] trained & saved to ./checkpoints/stage1/news_1990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 13647.94 examples/s]\n",
      "/root/scripts/train_mlm_stage1.py:83: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "100%|██████████| 313/313 [00:12<00:00, 25.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 8.0594, 'grad_norm': 2.368443727493286, 'learning_rate': 0.00034185303514377, 'epoch': 0.32}\n",
      "{'loss': 7.2906, 'grad_norm': 2.2948131561279297, 'learning_rate': 0.00018210862619808308, 'epoch': 0.64}\n",
      "{'loss': 7.2162, 'grad_norm': 2.1447134017944336, 'learning_rate': 2.2364217252396165e-05, 'epoch': 0.96}\n",
      "{'train_runtime': 12.0891, 'train_samples_per_second': 827.189, 'train_steps_per_second': 25.891, 'train_loss': 7.505405584463296, 'epoch': 1.0}\n",
      "[OK] trained & saved to ./checkpoints/stage1/paper_1990\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python scripts/train_mlm_stage1.py \\\n",
    "  --dataset_dir ./datasets/news_1990 \\\n",
    "  --tokenizer_json ./tokenizer/tokenizer.json \\\n",
    "  --out_dir ./checkpoints/stage1/news_1990 \\\n",
    "  --mlm_prob 0.15 \\\n",
    "  --epochs 1\n",
    "\n",
    "python scripts/train_mlm_stage1.py \\\n",
    "  --dataset_dir ./datasets/paper_1990 \\\n",
    "  --tokenizer_json ./tokenizer/tokenizer.json \\\n",
    "  --out_dir ./checkpoints/stage1/paper_1990 \\\n",
    "  --epochs 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a46e01d-7d25-4847-8870-d493466b0677",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 18723.46 examples/s]\n",
      "/root/scripts/train_annualbert_nodecollator.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.9017, 'grad_norm': 1.667444109916687, 'learning_rate': 0.00034185303514377, 'epoch': 0.32}\n",
      "{'loss': 5.6184, 'grad_norm': 1.8916382789611816, 'learning_rate': 0.00018210862619808308, 'epoch': 0.64}\n",
      "{'loss': 5.5754, 'grad_norm': 1.874609112739563, 'learning_rate': 2.2364217252396165e-05, 'epoch': 0.96}\n",
      "{'train_runtime': 11.8091, 'train_samples_per_second': 846.801, 'train_steps_per_second': 26.505, 'train_loss': 5.693990079739604, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:11<00:00, 26.51it/s]\n",
      "/root/scripts/train_annualbert_nodecollator.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.2101, 'grad_norm': 5.29792594909668, 'learning_rate': 0.0001380191693290735, 'epoch': 0.32}\n",
      "{'loss': 2.8993, 'grad_norm': 2.6127431392669678, 'learning_rate': 7.412140575079873e-05, 'epoch': 0.64}\n",
      "{'loss': 2.3996, 'grad_norm': 4.429743766784668, 'learning_rate': 1.0223642172523962e-05, 'epoch': 0.96}\n",
      "{'train_runtime': 11.5279, 'train_samples_per_second': 867.458, 'train_steps_per_second': 27.151, 'train_loss': 3.7868585556079024, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:11<00:00, 27.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] finished year 1991: stage1->./checkpoints/annual_node/news/year=1991/stage1, stage2->./checkpoints/annual_node/news/year=1991/stage2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 24489.48 examples/s]\n",
      "/root/scripts/train_annualbert_nodecollator.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.2125, 'grad_norm': 1.8737698793411255, 'learning_rate': 0.00034345047923322686, 'epoch': 0.32}\n",
      "{'loss': 5.7027, 'grad_norm': 1.5505715608596802, 'learning_rate': 0.00018370607028753993, 'epoch': 0.64}\n",
      "{'loss': 5.6684, 'grad_norm': 1.7985942363739014, 'learning_rate': 2.3961661341853036e-05, 'epoch': 0.96}\n",
      "{'train_runtime': 10.8659, 'train_samples_per_second': 920.307, 'train_steps_per_second': 28.806, 'train_loss': 5.848622623723917, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:10<00:00, 28.81it/s]\n",
      "/root/scripts/train_annualbert_nodecollator.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7795, 'grad_norm': 3.9916367530822754, 'learning_rate': 0.0001380191693290735, 'epoch': 0.32}\n",
      "{'loss': 2.6148, 'grad_norm': 2.7792694568634033, 'learning_rate': 7.412140575079873e-05, 'epoch': 0.64}\n",
      "{'loss': 2.4662, 'grad_norm': 1.9664013385772705, 'learning_rate': 1.0223642172523962e-05, 'epoch': 0.96}\n",
      "{'train_runtime': 11.0648, 'train_samples_per_second': 903.771, 'train_steps_per_second': 28.288, 'train_loss': 2.9455660006489617, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:11<00:00, 28.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] finished year 1992: stage1->./checkpoints/annual_node/news/year=1992/stage1, stage2->./checkpoints/annual_node/news/year=1992/stage2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 26000.06 examples/s]\n",
      "/root/scripts/train_annualbert_nodecollator.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.9642, 'grad_norm': 1.663785696029663, 'learning_rate': 0.0003450479233226837, 'epoch': 0.32}\n",
      "{'loss': 5.7571, 'grad_norm': 2.1150448322296143, 'learning_rate': 0.0001853035143769968, 'epoch': 0.64}\n",
      "{'loss': 5.7165, 'grad_norm': 1.5881599187850952, 'learning_rate': 2.5559105431309903e-05, 'epoch': 0.96}\n",
      "{'train_runtime': 11.2142, 'train_samples_per_second': 891.729, 'train_steps_per_second': 27.911, 'train_loss': 5.809351058813711, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:11<00:00, 27.91it/s]\n",
      "/root/scripts/train_annualbert_nodecollator.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6135, 'grad_norm': 1.8636764287948608, 'learning_rate': 0.00013865814696485625, 'epoch': 0.32}\n",
      "{'loss': 2.5105, 'grad_norm': 2.017517566680908, 'learning_rate': 7.476038338658148e-05, 'epoch': 0.64}\n",
      "{'loss': 2.5651, 'grad_norm': 1.4660365581512451, 'learning_rate': 1.086261980830671e-05, 'epoch': 0.96}\n",
      "{'train_runtime': 11.7521, 'train_samples_per_second': 850.914, 'train_steps_per_second': 26.634, 'train_loss': 2.880206805829423, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:11<00:00, 26.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] finished year 1993: stage1->./checkpoints/annual_node/news/year=1993/stage1, stage2->./checkpoints/annual_node/news/year=1993/stage2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 24734.21 examples/s]\n",
      "/root/scripts/train_annualbert_nodecollator.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.9832, 'grad_norm': 1.8968205451965332, 'learning_rate': 0.0003450479233226837, 'epoch': 0.32}\n",
      "{'loss': 5.7336, 'grad_norm': 2.0235371589660645, 'learning_rate': 0.0001853035143769968, 'epoch': 0.64}\n",
      "{'loss': 5.7327, 'grad_norm': 1.753794550895691, 'learning_rate': 2.5559105431309903e-05, 'epoch': 0.96}\n",
      "{'train_runtime': 11.426, 'train_samples_per_second': 875.199, 'train_steps_per_second': 27.394, 'train_loss': 5.808436579597644, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:11<00:00, 27.39it/s]\n",
      "/root/scripts/train_annualbert_nodecollator.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8505, 'grad_norm': 3.786292791366577, 'learning_rate': 0.00013865814696485625, 'epoch': 0.32}\n",
      "{'loss': 2.5022, 'grad_norm': 1.7127277851104736, 'learning_rate': 7.476038338658148e-05, 'epoch': 0.64}\n",
      "{'loss': 2.5591, 'grad_norm': 3.0509893894195557, 'learning_rate': 1.086261980830671e-05, 'epoch': 0.96}\n",
      "{'train_runtime': 11.7154, 'train_samples_per_second': 853.575, 'train_steps_per_second': 26.717, 'train_loss': 2.6264378849309855, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:11<00:00, 26.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] finished year 1994: stage1->./checkpoints/annual_node/news/year=1994/stage1, stage2->./checkpoints/annual_node/news/year=1994/stage2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 25011.85 examples/s]\n",
      "/root/scripts/train_annualbert_nodecollator.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.9624, 'grad_norm': 1.5453206300735474, 'learning_rate': 0.0003450479233226837, 'epoch': 0.32}\n",
      "{'loss': 5.771, 'grad_norm': 1.6939735412597656, 'learning_rate': 0.0001853035143769968, 'epoch': 0.64}\n",
      "{'loss': 5.7535, 'grad_norm': 1.7110267877578735, 'learning_rate': 2.5559105431309903e-05, 'epoch': 0.96}\n",
      "{'train_runtime': 11.9395, 'train_samples_per_second': 837.559, 'train_steps_per_second': 26.216, 'train_loss': 5.825950013182034, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:11<00:00, 26.22it/s]\n",
      "/root/scripts/train_annualbert_nodecollator.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.3593, 'grad_norm': 1.9672210216522217, 'learning_rate': 0.00013865814696485625, 'epoch': 0.32}\n",
      "{'loss': 2.336, 'grad_norm': 1.9547501802444458, 'learning_rate': 7.476038338658148e-05, 'epoch': 0.64}\n",
      "{'loss': 2.2637, 'grad_norm': 2.0428218841552734, 'learning_rate': 1.086261980830671e-05, 'epoch': 0.96}\n",
      "{'train_runtime': 12.2086, 'train_samples_per_second': 819.094, 'train_steps_per_second': 25.638, 'train_loss': 2.6317086021740215, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:12<00:00, 25.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] finished year 1995: stage1->./checkpoints/annual_node/news/year=1995/stage1, stage2->./checkpoints/annual_node/news/year=1995/stage2\n",
      "[DONE] AnnualBERT continual training finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 16804.57 examples/s]\n",
      "/root/scripts/train_annualbert_nodecollator.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "100%|██████████| 313/313 [00:11<00:00, 27.02it/s]\n",
      "/root/scripts/train_annualbert_nodecollator.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.5669, 'grad_norm': 2.2332234382629395, 'learning_rate': 0.00034185303514377, 'epoch': 0.32}\n",
      "{'loss': 7.1374, 'grad_norm': 2.206836700439453, 'learning_rate': 0.00018210862619808308, 'epoch': 0.64}\n",
      "{'loss': 7.1279, 'grad_norm': 2.1242403984069824, 'learning_rate': 2.2364217252396165e-05, 'epoch': 0.96}\n",
      "{'train_runtime': 11.5842, 'train_samples_per_second': 863.244, 'train_steps_per_second': 27.02, 'train_loss': 7.264557981643433, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:11<00:00, 27.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.2829, 'grad_norm': 3.8438799381256104, 'learning_rate': 0.00013865814696485625, 'epoch': 0.32}\n",
      "{'loss': 2.2859, 'grad_norm': 1.9737212657928467, 'learning_rate': 7.476038338658148e-05, 'epoch': 0.64}\n",
      "{'loss': 2.0912, 'grad_norm': 3.0224156379699707, 'learning_rate': 1.086261980830671e-05, 'epoch': 0.96}\n",
      "{'train_runtime': 11.3672, 'train_samples_per_second': 879.728, 'train_steps_per_second': 27.535, 'train_loss': 3.1600221627817366, 'epoch': 1.0}\n",
      "[OK] finished year 1991: stage1->./checkpoints/annual_node/paper/year=1991/stage1, stage2->./checkpoints/annual_node/paper/year=1991/stage2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 19121.10 examples/s]\n",
      "/root/scripts/train_annualbert_nodecollator.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "100%|██████████| 313/313 [00:11<00:00, 26.90it/s]\n",
      "/root/scripts/train_annualbert_nodecollator.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.2221, 'grad_norm': 2.1696054935455322, 'learning_rate': 0.00034345047923322686, 'epoch': 0.32}\n",
      "{'loss': 7.1292, 'grad_norm': 2.3777763843536377, 'learning_rate': 0.00018370607028753993, 'epoch': 0.64}\n",
      "{'loss': 7.0865, 'grad_norm': 2.515995502471924, 'learning_rate': 2.3961661341853036e-05, 'epoch': 0.96}\n",
      "{'train_runtime': 11.6355, 'train_samples_per_second': 859.441, 'train_steps_per_second': 26.901, 'train_loss': 7.140059449802192, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:12<00:00, 25.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8673, 'grad_norm': 1.4236143827438354, 'learning_rate': 0.00013865814696485625, 'epoch': 0.32}\n",
      "{'loss': 2.161, 'grad_norm': 2.005970001220703, 'learning_rate': 7.476038338658148e-05, 'epoch': 0.64}\n",
      "{'loss': 2.1291, 'grad_norm': 1.8846654891967773, 'learning_rate': 1.086261980830671e-05, 'epoch': 0.96}\n",
      "{'train_runtime': 12.3196, 'train_samples_per_second': 811.714, 'train_steps_per_second': 25.407, 'train_loss': 2.3883199965991913, 'epoch': 1.0}\n",
      "[OK] finished year 1992: stage1->./checkpoints/annual_node/paper/year=1992/stage1, stage2->./checkpoints/annual_node/paper/year=1992/stage2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 21220.25 examples/s]\n",
      "/root/scripts/train_annualbert_nodecollator.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "100%|██████████| 313/313 [00:11<00:00, 27.66it/s]\n",
      "/root/scripts/train_annualbert_nodecollator.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.2359, 'grad_norm': 1.8294185400009155, 'learning_rate': 0.0003450479233226837, 'epoch': 0.32}\n",
      "{'loss': 7.0868, 'grad_norm': 2.2416481971740723, 'learning_rate': 0.0001853035143769968, 'epoch': 0.64}\n",
      "{'loss': 7.0161, 'grad_norm': 1.859709620475769, 'learning_rate': 2.5559105431309903e-05, 'epoch': 0.96}\n",
      "{'train_runtime': 11.3177, 'train_samples_per_second': 883.571, 'train_steps_per_second': 27.656, 'train_loss': 7.10976000411061, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:11<00:00, 27.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7618, 'grad_norm': 3.5079615116119385, 'learning_rate': 0.000139297124600639, 'epoch': 0.32}\n",
      "{'loss': 2.0945, 'grad_norm': 1.563826322555542, 'learning_rate': 7.539936102236423e-05, 'epoch': 0.64}\n",
      "{'loss': 2.0692, 'grad_norm': 2.4770925045013428, 'learning_rate': 1.1501597444089457e-05, 'epoch': 0.96}\n",
      "{'train_runtime': 11.4859, 'train_samples_per_second': 870.633, 'train_steps_per_second': 27.251, 'train_loss': 2.3089217408396565, 'epoch': 1.0}\n",
      "[OK] finished year 1993: stage1->./checkpoints/annual_node/paper/year=1993/stage1, stage2->./checkpoints/annual_node/paper/year=1993/stage2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 21076.29 examples/s]\n",
      "/root/scripts/train_annualbert_nodecollator.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "100%|██████████| 313/313 [00:12<00:00, 26.01it/s]\n",
      "/root/scripts/train_annualbert_nodecollator.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.17, 'grad_norm': 1.9389655590057373, 'learning_rate': 0.0003450479233226837, 'epoch': 0.32}\n",
      "{'loss': 7.1307, 'grad_norm': 2.240368604660034, 'learning_rate': 0.0001853035143769968, 'epoch': 0.64}\n",
      "{'loss': 7.073, 'grad_norm': 1.997167944908142, 'learning_rate': 2.5559105431309903e-05, 'epoch': 0.96}\n",
      "{'train_runtime': 12.0353, 'train_samples_per_second': 830.89, 'train_steps_per_second': 26.007, 'train_loss': 7.1190155565548245, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:11<00:00, 26.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8049, 'grad_norm': 2.836848020553589, 'learning_rate': 0.000139297124600639, 'epoch': 0.32}\n",
      "{'loss': 2.1308, 'grad_norm': 2.2705090045928955, 'learning_rate': 7.539936102236423e-05, 'epoch': 0.64}\n",
      "{'loss': 2.1636, 'grad_norm': 1.5034745931625366, 'learning_rate': 1.1501597444089457e-05, 'epoch': 0.96}\n",
      "{'train_runtime': 11.5988, 'train_samples_per_second': 862.156, 'train_steps_per_second': 26.985, 'train_loss': 2.359138586269781, 'epoch': 1.0}\n",
      "[OK] finished year 1994: stage1->./checkpoints/annual_node/paper/year=1994/stage1, stage2->./checkpoints/annual_node/paper/year=1994/stage2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 20311.49 examples/s]\n",
      "/root/scripts/train_annualbert_nodecollator.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "100%|██████████| 313/313 [00:11<00:00, 27.66it/s]\n",
      "/root/scripts/train_annualbert_nodecollator.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.1745, 'grad_norm': 1.8829330205917358, 'learning_rate': 0.0003450479233226837, 'epoch': 0.32}\n",
      "{'loss': 7.057, 'grad_norm': 1.8609330654144287, 'learning_rate': 0.0001853035143769968, 'epoch': 0.64}\n",
      "{'loss': 7.0767, 'grad_norm': 2.0850014686584473, 'learning_rate': 2.5559105431309903e-05, 'epoch': 0.96}\n",
      "{'train_runtime': 11.3173, 'train_samples_per_second': 883.599, 'train_steps_per_second': 27.657, 'train_loss': 7.101863727021141, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:11<00:00, 27.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7365, 'grad_norm': 1.448035717010498, 'learning_rate': 0.000139297124600639, 'epoch': 0.32}\n",
      "{'loss': 2.1067, 'grad_norm': 1.3397789001464844, 'learning_rate': 7.539936102236423e-05, 'epoch': 0.64}\n",
      "{'loss': 2.2033, 'grad_norm': 2.230212688446045, 'learning_rate': 1.1501597444089457e-05, 'epoch': 0.96}\n",
      "{'train_runtime': 11.5671, 'train_samples_per_second': 864.522, 'train_steps_per_second': 27.06, 'train_loss': 2.3373662930327104, 'epoch': 1.0}\n",
      "[OK] finished year 1995: stage1->./checkpoints/annual_node/paper/year=1995/stage1, stage2->./checkpoints/annual_node/paper/year=1995/stage2\n",
      "[DONE] AnnualBERT continual training finished.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -u scripts/train_annualbert_nodecollator.py \\\n",
    "  --domain news \\\n",
    "  --dataset_root ./datasets \\\n",
    "  --tokenizer_json ./tokenizer/tokenizer.json \\\n",
    "  --ckpt_root ./checkpoints/annual_node \\\n",
    "  --years 1990 1991 1992 1993 1994 1995 \\\n",
    "  --seed_ckpt ./checkpoints/stage1/news_1990 \\\n",
    "  --stage2_exact_k_masks 1\n",
    "\n",
    "python scripts/train_annualbert_nodecollator.py \\\n",
    "  --domain paper \\\n",
    "  --dataset_root ./datasets \\\n",
    "  --tokenizer_json ./tokenizer/tokenizer.json \\\n",
    "  --ckpt_root ./checkpoints/annual_node \\\n",
    "  --years 1990 1991 1992 1993 1994 1995 \\\n",
    "  --seed_ckpt ./checkpoints/stage1/paper_1990 \\\n",
    "  --stage2_exact_k_masks 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "133ac461-993f-4d62-8632-14f80856bc2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RUN] python -u scripts/extract_neighbors_encoded.py --tokenizer_json ./tokenizer/tokenizer.json --checkpoint_dir ./checkpoints/annual_node/news/year=1991/stage2 --corpus_path ./corpus/news_1991.txt --target_token information --side both --topk 300 --num_contexts 1000 --out_json ./outputs/neighbor_mask/news_1991_information_neighbors.json\n",
      "[OK] saved -> ./outputs/neighbor_mask/news_1991_information_neighbors.json\n",
      "used_left=0, used_right=0\n",
      "[RUN] python -u scripts/extract_neighbors_encoded.py --tokenizer_json ./tokenizer/tokenizer.json --checkpoint_dir ./checkpoints/annual_node/news/year=1992/stage2 --corpus_path ./corpus/news_1992.txt --target_token information --side both --topk 300 --num_contexts 1000 --out_json ./outputs/neighbor_mask/news_1992_information_neighbors.json\n",
      "[OK] saved -> ./outputs/neighbor_mask/news_1992_information_neighbors.json\n",
      "used_left=0, used_right=0\n",
      "[RUN] python -u scripts/extract_neighbors_encoded.py --tokenizer_json ./tokenizer/tokenizer.json --checkpoint_dir ./checkpoints/annual_node/news/year=1993/stage2 --corpus_path ./corpus/news_1993.txt --target_token information --side both --topk 300 --num_contexts 1000 --out_json ./outputs/neighbor_mask/news_1993_information_neighbors.json\n",
      "[OK] saved -> ./outputs/neighbor_mask/news_1993_information_neighbors.json\n",
      "used_left=0, used_right=0\n",
      "[RUN] python -u scripts/extract_neighbors_encoded.py --tokenizer_json ./tokenizer/tokenizer.json --checkpoint_dir ./checkpoints/annual_node/news/year=1994/stage2 --corpus_path ./corpus/news_1994.txt --target_token information --side both --topk 300 --num_contexts 1000 --out_json ./outputs/neighbor_mask/news_1994_information_neighbors.json\n",
      "[OK] saved -> ./outputs/neighbor_mask/news_1994_information_neighbors.json\n",
      "used_left=0, used_right=0\n",
      "[RUN] python -u scripts/extract_neighbors_encoded.py --tokenizer_json ./tokenizer/tokenizer.json --checkpoint_dir ./checkpoints/annual_node/news/year=1995/stage2 --corpus_path ./corpus/news_1995.txt --target_token information --side both --topk 300 --num_contexts 1000 --out_json ./outputs/neighbor_mask/news_1995_information_neighbors.json\n",
      "[OK] saved -> ./outputs/neighbor_mask/news_1995_information_neighbors.json\n",
      "used_left=0, used_right=0\n",
      "[DONE] ran=5, skipped=0, failed=0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -u ./scripts/batch_extract_neighbors.py \\\n",
    "  --years 1991 1992 1993 1994 1995 \\\n",
    "  --domains news \\\n",
    "  --tokenizer_json ./tokenizer/tokenizer.json \\\n",
    "  --ckpt_root ./checkpoints/annual_node \\\n",
    "  --corpus_root ./corpus \\\n",
    "  --out_root ./outputs/neighbor_mask \\\n",
    "  --targets \\\n",
    "    \"information\" \\\n",
    "  --topk 300 --num_contexts 1000 --side both --stage stage2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa2a8349-8bf3-4043-aa19-93db83e58d27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>domain</th>\n",
       "      <th>side</th>\n",
       "      <th>rank</th>\n",
       "      <th>token</th>\n",
       "      <th>avg_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>1</td>\n",
       "      <td>automation</td>\n",
       "      <td>0.014782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>2</td>\n",
       "      <td>banks</td>\n",
       "      <td>0.010451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>3</td>\n",
       "      <td>systems</td>\n",
       "      <td>0.009469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>4</td>\n",
       "      <td>industry</td>\n",
       "      <td>0.008359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>5</td>\n",
       "      <td>banking</td>\n",
       "      <td>0.006954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>6</td>\n",
       "      <td>software</td>\n",
       "      <td>0.006103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>7</td>\n",
       "      <td>information</td>\n",
       "      <td>0.005822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>8</td>\n",
       "      <td>computers</td>\n",
       "      <td>0.004588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>9</td>\n",
       "      <td>services</td>\n",
       "      <td>0.004346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>10</td>\n",
       "      <td>management</td>\n",
       "      <td>0.004288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>11</td>\n",
       "      <td>credit</td>\n",
       "      <td>0.004030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>12</td>\n",
       "      <td>regulation</td>\n",
       "      <td>0.002658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>13</td>\n",
       "      <td>technology</td>\n",
       "      <td>0.002589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>14</td>\n",
       "      <td>securities</td>\n",
       "      <td>0.002492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>15</td>\n",
       "      <td>government</td>\n",
       "      <td>0.002163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>16</td>\n",
       "      <td>profiles</td>\n",
       "      <td>0.002035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>17</td>\n",
       "      <td>health</td>\n",
       "      <td>0.001982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>18</td>\n",
       "      <td>marketing</td>\n",
       "      <td>0.001915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>19</td>\n",
       "      <td>costs</td>\n",
       "      <td>0.001860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>20</td>\n",
       "      <td>research</td>\n",
       "      <td>0.001758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1992</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>1</td>\n",
       "      <td>industry</td>\n",
       "      <td>0.013668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1992</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>2</td>\n",
       "      <td>systems</td>\n",
       "      <td>0.010752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1992</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>3</td>\n",
       "      <td>automation</td>\n",
       "      <td>0.008082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1992</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>4</td>\n",
       "      <td>software</td>\n",
       "      <td>0.007748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1992</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>5</td>\n",
       "      <td>information</td>\n",
       "      <td>0.007726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1992</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>6</td>\n",
       "      <td>management</td>\n",
       "      <td>0.006250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1992</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>7</td>\n",
       "      <td>services</td>\n",
       "      <td>0.005242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1992</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>8</td>\n",
       "      <td>computers</td>\n",
       "      <td>0.005216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1992</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>9</td>\n",
       "      <td>banks</td>\n",
       "      <td>0.004768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1992</td>\n",
       "      <td>news</td>\n",
       "      <td>left</td>\n",
       "      <td>10</td>\n",
       "      <td>pacific</td>\n",
       "      <td>0.003631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year domain  side  rank        token  avg_prob\n",
       "0   1991   news  left     1   automation  0.014782\n",
       "1   1991   news  left     2        banks  0.010451\n",
       "2   1991   news  left     3      systems  0.009469\n",
       "3   1991   news  left     4     industry  0.008359\n",
       "4   1991   news  left     5      banking  0.006954\n",
       "5   1991   news  left     6     software  0.006103\n",
       "6   1991   news  left     7  information  0.005822\n",
       "7   1991   news  left     8    computers  0.004588\n",
       "8   1991   news  left     9     services  0.004346\n",
       "9   1991   news  left    10   management  0.004288\n",
       "10  1991   news  left    11       credit  0.004030\n",
       "11  1991   news  left    12   regulation  0.002658\n",
       "12  1991   news  left    13   technology  0.002589\n",
       "13  1991   news  left    14   securities  0.002492\n",
       "14  1991   news  left    15   government  0.002163\n",
       "15  1991   news  left    16     profiles  0.002035\n",
       "16  1991   news  left    17       health  0.001982\n",
       "17  1991   news  left    18    marketing  0.001915\n",
       "18  1991   news  left    19        costs  0.001860\n",
       "19  1991   news  left    20     research  0.001758\n",
       "20  1992   news  left     1     industry  0.013668\n",
       "21  1992   news  left     2      systems  0.010752\n",
       "22  1992   news  left     3   automation  0.008082\n",
       "23  1992   news  left     4     software  0.007748\n",
       "24  1992   news  left     5  information  0.007726\n",
       "25  1992   news  left     6   management  0.006250\n",
       "26  1992   news  left     7     services  0.005242\n",
       "27  1992   news  left     8    computers  0.005216\n",
       "28  1992   news  left     9        banks  0.004768\n",
       "29  1992   news  left    10      pacific  0.003631"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>domain</th>\n",
       "      <th>side</th>\n",
       "      <th>rank</th>\n",
       "      <th>token</th>\n",
       "      <th>avg_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>1</td>\n",
       "      <td>automation</td>\n",
       "      <td>0.014782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>2</td>\n",
       "      <td>banks</td>\n",
       "      <td>0.010451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>3</td>\n",
       "      <td>systems</td>\n",
       "      <td>0.009469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>4</td>\n",
       "      <td>industry</td>\n",
       "      <td>0.008359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>5</td>\n",
       "      <td>banking</td>\n",
       "      <td>0.006954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>6</td>\n",
       "      <td>software</td>\n",
       "      <td>0.006103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>7</td>\n",
       "      <td>information</td>\n",
       "      <td>0.005822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>8</td>\n",
       "      <td>computers</td>\n",
       "      <td>0.004588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>9</td>\n",
       "      <td>services</td>\n",
       "      <td>0.004347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>10</td>\n",
       "      <td>management</td>\n",
       "      <td>0.004288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>11</td>\n",
       "      <td>credit</td>\n",
       "      <td>0.004030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>12</td>\n",
       "      <td>regulation</td>\n",
       "      <td>0.002658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>13</td>\n",
       "      <td>technology</td>\n",
       "      <td>0.002589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>14</td>\n",
       "      <td>securities</td>\n",
       "      <td>0.002492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>15</td>\n",
       "      <td>government</td>\n",
       "      <td>0.002163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>16</td>\n",
       "      <td>profiles</td>\n",
       "      <td>0.002035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>17</td>\n",
       "      <td>health</td>\n",
       "      <td>0.001982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>18</td>\n",
       "      <td>marketing</td>\n",
       "      <td>0.001915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>19</td>\n",
       "      <td>costs</td>\n",
       "      <td>0.001860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1991</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>20</td>\n",
       "      <td>research</td>\n",
       "      <td>0.001758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1992</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>1</td>\n",
       "      <td>industry</td>\n",
       "      <td>0.013669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1992</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>2</td>\n",
       "      <td>systems</td>\n",
       "      <td>0.010753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1992</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>3</td>\n",
       "      <td>automation</td>\n",
       "      <td>0.008082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1992</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>4</td>\n",
       "      <td>software</td>\n",
       "      <td>0.007748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1992</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>5</td>\n",
       "      <td>information</td>\n",
       "      <td>0.007727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1992</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>6</td>\n",
       "      <td>management</td>\n",
       "      <td>0.006250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1992</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>7</td>\n",
       "      <td>services</td>\n",
       "      <td>0.005242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1992</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>8</td>\n",
       "      <td>computers</td>\n",
       "      <td>0.005217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1992</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>9</td>\n",
       "      <td>banks</td>\n",
       "      <td>0.004768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1992</td>\n",
       "      <td>news</td>\n",
       "      <td>right</td>\n",
       "      <td>10</td>\n",
       "      <td>pacific</td>\n",
       "      <td>0.003632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year domain   side  rank        token  avg_prob\n",
       "0   1991   news  right     1   automation  0.014782\n",
       "1   1991   news  right     2        banks  0.010451\n",
       "2   1991   news  right     3      systems  0.009469\n",
       "3   1991   news  right     4     industry  0.008359\n",
       "4   1991   news  right     5      banking  0.006954\n",
       "5   1991   news  right     6     software  0.006103\n",
       "6   1991   news  right     7  information  0.005822\n",
       "7   1991   news  right     8    computers  0.004588\n",
       "8   1991   news  right     9     services  0.004347\n",
       "9   1991   news  right    10   management  0.004288\n",
       "10  1991   news  right    11       credit  0.004030\n",
       "11  1991   news  right    12   regulation  0.002658\n",
       "12  1991   news  right    13   technology  0.002589\n",
       "13  1991   news  right    14   securities  0.002492\n",
       "14  1991   news  right    15   government  0.002163\n",
       "15  1991   news  right    16     profiles  0.002035\n",
       "16  1991   news  right    17       health  0.001982\n",
       "17  1991   news  right    18    marketing  0.001915\n",
       "18  1991   news  right    19        costs  0.001860\n",
       "19  1991   news  right    20     research  0.001758\n",
       "20  1992   news  right     1     industry  0.013669\n",
       "21  1992   news  right     2      systems  0.010753\n",
       "22  1992   news  right     3   automation  0.008082\n",
       "23  1992   news  right     4     software  0.007748\n",
       "24  1992   news  right     5  information  0.007727\n",
       "25  1992   news  right     6   management  0.006250\n",
       "26  1992   news  right     7     services  0.005242\n",
       "27  1992   news  right     8    computers  0.005217\n",
       "28  1992   news  right     9        banks  0.004768\n",
       "29  1992   news  right    10      pacific  0.003632"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "target = \"artificial▁intelligence\"\n",
    "years = [1991,1992,1993,1994,1995]\n",
    "\n",
    "def load_top(domain, year, side, k=20):\n",
    "    p = Path(f\"./outputs/neighbor_mask/{domain}_{year}_{target}_neighbors.json\")\n",
    "    obj = json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "    key = \"topk_left\" if side==\"left\" else \"topk_right\"\n",
    "    rows = obj[key][:k]\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.insert(0, \"year\", year)\n",
    "    df.insert(1, \"domain\", domain)\n",
    "    df.insert(2, \"side\", side)\n",
    "    df.insert(3, \"rank\", range(1, len(df)+1))\n",
    "    return df\n",
    "\n",
    "news_left  = pd.concat([load_top(\"news\", y, \"left\", 20) for y in years], ignore_index=True)\n",
    "news_right = pd.concat([load_top(\"news\", y, \"right\", 20) for y in years], ignore_index=True)\n",
    "\n",
    "display(news_left.head(30))\n",
    "display(news_right.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be66454e-bc06-4a5e-9ace-f2abd6ba3928",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RUN] python -u scripts/extract_neighbors_encoded.py --tokenizer_json ./tokenizer/tokenizer.json --checkpoint_dir ./checkpoints/annual_node/paper/year=1991/stage2 --corpus_path ./corpus/paper_1991.txt --target_token artificial▁intelligence --side both --topk 100 --num_contexts 1000 --out_json ./outputs/neighbor_mask/paper_1991_artificial▁intelligence_neighbors.json\n",
      "[OK] saved -> ./outputs/neighbor_mask/paper_1991_artificial▁intelligence_neighbors.json\n",
      "used_left=0, used_right=0\n",
      "[RUN] python -u scripts/extract_neighbors_encoded.py --tokenizer_json ./tokenizer/tokenizer.json --checkpoint_dir ./checkpoints/annual_node/paper/year=1992/stage2 --corpus_path ./corpus/paper_1992.txt --target_token artificial▁intelligence --side both --topk 100 --num_contexts 1000 --out_json ./outputs/neighbor_mask/paper_1992_artificial▁intelligence_neighbors.json\n",
      "[OK] saved -> ./outputs/neighbor_mask/paper_1992_artificial▁intelligence_neighbors.json\n",
      "used_left=0, used_right=0\n",
      "[RUN] python -u scripts/extract_neighbors_encoded.py --tokenizer_json ./tokenizer/tokenizer.json --checkpoint_dir ./checkpoints/annual_node/paper/year=1993/stage2 --corpus_path ./corpus/paper_1993.txt --target_token artificial▁intelligence --side both --topk 100 --num_contexts 1000 --out_json ./outputs/neighbor_mask/paper_1993_artificial▁intelligence_neighbors.json\n",
      "[OK] saved -> ./outputs/neighbor_mask/paper_1993_artificial▁intelligence_neighbors.json\n",
      "used_left=0, used_right=0\n",
      "[RUN] python -u scripts/extract_neighbors_encoded.py --tokenizer_json ./tokenizer/tokenizer.json --checkpoint_dir ./checkpoints/annual_node/paper/year=1994/stage2 --corpus_path ./corpus/paper_1994.txt --target_token artificial▁intelligence --side both --topk 100 --num_contexts 1000 --out_json ./outputs/neighbor_mask/paper_1994_artificial▁intelligence_neighbors.json\n",
      "[OK] saved -> ./outputs/neighbor_mask/paper_1994_artificial▁intelligence_neighbors.json\n",
      "used_left=0, used_right=0\n",
      "[RUN] python -u scripts/extract_neighbors_encoded.py --tokenizer_json ./tokenizer/tokenizer.json --checkpoint_dir ./checkpoints/annual_node/paper/year=1995/stage2 --corpus_path ./corpus/paper_1995.txt --target_token artificial▁intelligence --side both --topk 100 --num_contexts 1000 --out_json ./outputs/neighbor_mask/paper_1995_artificial▁intelligence_neighbors.json\n",
      "[OK] saved -> ./outputs/neighbor_mask/paper_1995_artificial▁intelligence_neighbors.json\n",
      "used_left=0, used_right=0\n",
      "[DONE] ran=5, skipped=0, failed=0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -u scripts/batch_extract_neighbors.py \\\n",
    "  --years 1991 1992 1993 1994 1995 \\\n",
    "  --domains paper \\\n",
    "  --targets \\\n",
    "    \"artificial▁intelligence\" \\\n",
    "  --tokenizer_json ./tokenizer/tokenizer.json \\\n",
    "  --ckpt_root ./checkpoints/annual_node \\\n",
    "  --corpus_root ./corpus \\\n",
    "  --out_root ./outputs/neighbor_mask \\\n",
    "  --topk 100 \\\n",
    "  --num_contexts 1000 \\\n",
    "  --side both \\\n",
    "  --stage stage2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "930eb263-79d9-4f62-b68b-57e927498065",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'outputs/neighbor_mask/paper_1993_information_neighbors.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     df\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 19\u001b[0m news_left  \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([load_top(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaper\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m20\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m years], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     20\u001b[0m news_right \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([load_top(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaper\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m20\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m years], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m display(news_left\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m30\u001b[39m))\n",
      "Cell \u001b[0;32mIn[16], line 19\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m     df\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 19\u001b[0m news_left  \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mload_top\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpaper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m years], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     20\u001b[0m news_right \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([load_top(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaper\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m20\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m years], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m display(news_left\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m30\u001b[39m))\n",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m, in \u001b[0;36mload_top\u001b[0;34m(domain, year, side, k)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_top\u001b[39m(domain, year, side, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m      8\u001b[0m     p \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./outputs/neighbor_mask/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdomain\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_neighbors.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     obj \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopk_left\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m side\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopk_right\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m     rows \u001b[38;5;241m=\u001b[39m obj[key][:k]\n",
      "File \u001b[0;32m/usr/lib/python3.10/pathlib.py:1134\u001b[0m, in \u001b[0;36mPath.read_text\u001b[0;34m(self, encoding, errors)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;124;03mOpen the file in text mode, read it, and close the file.\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[0;32m-> 1134\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/usr/lib/python3.10/pathlib.py:1119\u001b[0m, in \u001b[0;36mPath.open\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1118\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[0;32m-> 1119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'outputs/neighbor_mask/paper_1993_information_neighbors.json'"
     ]
    }
   ],
   "source": [
    "import json, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "target = \"artificial▁intelligence\"\n",
    "years = [1991,1992,1993,1994,1995]\n",
    "\n",
    "def load_top(domain, year, side, k=20):\n",
    "    p = Path(f\"./outputs/neighbor_mask/{domain}_{year}_{target}_neighbors.json\")\n",
    "    obj = json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "    key = \"topk_left\" if side==\"left\" else \"topk_right\"\n",
    "    rows = obj[key][:k]\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.insert(0, \"year\", year)\n",
    "    df.insert(1, \"domain\", domain)\n",
    "    df.insert(2, \"side\", side)\n",
    "    df.insert(3, \"rank\", range(1, len(df)+1))\n",
    "    return df\n",
    "\n",
    "news_left  = pd.concat([load_top(\"paper\", y, \"left\", 20) for y in years], ignore_index=True)\n",
    "news_right = pd.concat([load_top(\"paper\", y, \"right\", 20) for y in years], ignore_index=True)\n",
    "\n",
    "display(news_left.head(30))\n",
    "display(news_right.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14a3749d-a7b8-44c4-8d2e-259363d131c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ for y in 1991 1992 1993 1994 1995\n",
      "+ echo 'YEAR 1991'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR 1991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ grep -c artificial▁intelligence ./corpus/paper_1991.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ for y in 1991 1992 1993 1994 1995\n",
      "+ echo 'YEAR 1992'\n",
      "+ grep -c artificial▁intelligence ./corpus/paper_1992.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR 1992\n",
      "114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ for y in 1991 1992 1993 1994 1995\n",
      "+ echo 'YEAR 1993'\n",
      "+ grep -c artificial▁intelligence ./corpus/paper_1993.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR 1993\n",
      "144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ for y in 1991 1992 1993 1994 1995\n",
      "+ echo 'YEAR 1994'\n",
      "+ grep -c artificial▁intelligence ./corpus/paper_1994.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR 1994\n",
      "118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ for y in 1991 1992 1993 1994 1995\n",
      "+ echo 'YEAR 1995'\n",
      "+ grep -c artificial▁intelligence ./corpus/paper_1995.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR 1995\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -euxo pipefail\n",
    "for y in 1991 1992 1993 1994 1995; do\n",
    "  echo \"YEAR $y\"\n",
    "  grep -c \"artificial▁intelligence\" ./corpus/paper_${y}.txt || true\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8465d7c-591a-4252-849d-58816e2b6d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ grep -n artificial ./tokenizer/concept_vocab_encoded.txt\n",
      "+ head -n 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683:Anticipation▁(artificial▁intelligence)\n",
      "752:Applications▁of▁artificial▁intelligence\n",
      "10597:Music▁and▁artificial▁intelligence\n",
      "18262:artificial▁intelligence\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -euxo pipefail\n",
    "grep -n \"artificial\" ./tokenizer/concept_vocab_encoded.txt | head -n 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e9bd639-8e9e-466d-908a-0ba7c0fa63b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ python -u scripts/compute_divergence.py --years 1991 1992 1993 1994 1995 --in_root ./outputs/neighbor_mask --target_token artificial▁intelligence --out_csv ./outputs/divergence/ai_neighbors_news_vs_paper.csv --side both\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] wrote -> ./outputs/divergence/ai_neighbors_news_vs_paper.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -euxo pipefail\n",
    "python -u scripts/compute_divergence.py \\\n",
    "  --years 1991 1992 1993 1994 1995 \\\n",
    "  --in_root ./outputs/neighbor_mask \\\n",
    "  --target_token \"artificial▁intelligence\" \\\n",
    "  --out_csv ./outputs/divergence/ai_neighbors_news_vs_paper.csv \\\n",
    "  --side both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3df902be-19be-4de8-a4ff-fc28d19b63ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auto] value_col -> 'token' 로 대체했습니다.\n",
      "[auto] value_col -> 'token' 로 대체했습니다.\n",
      "[auto] value_col -> 'token' 로 대체했습니다.\n",
      "\n",
      "=== [NEWS] artificial▁intelligence : left / right / (left+right) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>year</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>automation</td>\n",
       "      <td>industry</td>\n",
       "      <td>industry</td>\n",
       "      <td>industry</td>\n",
       "      <td>industry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banks</td>\n",
       "      <td>systems</td>\n",
       "      <td>automation</td>\n",
       "      <td>information</td>\n",
       "      <td>information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>systems</td>\n",
       "      <td>automation</td>\n",
       "      <td>software</td>\n",
       "      <td>systems</td>\n",
       "      <td>systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>industry</td>\n",
       "      <td>software</td>\n",
       "      <td>systems</td>\n",
       "      <td>automation</td>\n",
       "      <td>automation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>banking</td>\n",
       "      <td>information</td>\n",
       "      <td>information</td>\n",
       "      <td>management</td>\n",
       "      <td>software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>software</td>\n",
       "      <td>management</td>\n",
       "      <td>services</td>\n",
       "      <td>software</td>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>information</td>\n",
       "      <td>services</td>\n",
       "      <td>banking</td>\n",
       "      <td>services</td>\n",
       "      <td>services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>computers</td>\n",
       "      <td>computers</td>\n",
       "      <td>management</td>\n",
       "      <td>computers</td>\n",
       "      <td>banking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>services</td>\n",
       "      <td>banks</td>\n",
       "      <td>computers</td>\n",
       "      <td>business</td>\n",
       "      <td>computers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>management</td>\n",
       "      <td>pacific</td>\n",
       "      <td>pacific</td>\n",
       "      <td>banking</td>\n",
       "      <td>management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>credit</td>\n",
       "      <td>banking</td>\n",
       "      <td>banks</td>\n",
       "      <td>internet</td>\n",
       "      <td>pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>regulation</td>\n",
       "      <td>design</td>\n",
       "      <td>networks</td>\n",
       "      <td>communications</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>technology</td>\n",
       "      <td>health</td>\n",
       "      <td>business</td>\n",
       "      <td>pacific</td>\n",
       "      <td>presidents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>securities</td>\n",
       "      <td>alliances</td>\n",
       "      <td>research</td>\n",
       "      <td>health</td>\n",
       "      <td>networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>government</td>\n",
       "      <td>electronics</td>\n",
       "      <td>marketing</td>\n",
       "      <td>networks</td>\n",
       "      <td>credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>profiles</td>\n",
       "      <td>profiles</td>\n",
       "      <td>income</td>\n",
       "      <td>credit</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>health</td>\n",
       "      <td>networks</td>\n",
       "      <td>design</td>\n",
       "      <td>design</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>marketing</td>\n",
       "      <td>engineering</td>\n",
       "      <td>presidents</td>\n",
       "      <td>marketing</td>\n",
       "      <td>banks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>costs</td>\n",
       "      <td>government</td>\n",
       "      <td>profiles</td>\n",
       "      <td>technology</td>\n",
       "      <td>marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>research</td>\n",
       "      <td>business</td>\n",
       "      <td>technology</td>\n",
       "      <td>presidents</td>\n",
       "      <td>companies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "year         1991         1992         1993            1994         1995\n",
       "rank                                                                    \n",
       "1      automation     industry     industry        industry     industry\n",
       "2           banks      systems   automation     information  information\n",
       "3         systems   automation     software         systems      systems\n",
       "4        industry     software      systems      automation   automation\n",
       "5         banking  information  information      management     software\n",
       "6        software   management     services        software     internet\n",
       "7     information     services      banking        services     services\n",
       "8       computers    computers   management       computers      banking\n",
       "9        services        banks    computers        business    computers\n",
       "10     management      pacific      pacific         banking   management\n",
       "11         credit      banking        banks        internet      pacific\n",
       "12     regulation       design     networks  communications     business\n",
       "13     technology       health     business         pacific   presidents\n",
       "14     securities    alliances     research          health     networks\n",
       "15     government  electronics    marketing        networks       credit\n",
       "16       profiles     profiles       income          credit  electronics\n",
       "17         health     networks       design          design       health\n",
       "18      marketing  engineering   presidents       marketing        banks\n",
       "19          costs   government     profiles      technology    marketing\n",
       "20       research     business   technology      presidents    companies"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>year</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>automation</td>\n",
       "      <td>industry</td>\n",
       "      <td>industry</td>\n",
       "      <td>industry</td>\n",
       "      <td>industry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banks</td>\n",
       "      <td>systems</td>\n",
       "      <td>automation</td>\n",
       "      <td>information</td>\n",
       "      <td>information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>systems</td>\n",
       "      <td>automation</td>\n",
       "      <td>software</td>\n",
       "      <td>systems</td>\n",
       "      <td>systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>industry</td>\n",
       "      <td>software</td>\n",
       "      <td>systems</td>\n",
       "      <td>automation</td>\n",
       "      <td>automation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>banking</td>\n",
       "      <td>information</td>\n",
       "      <td>information</td>\n",
       "      <td>management</td>\n",
       "      <td>software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>software</td>\n",
       "      <td>management</td>\n",
       "      <td>services</td>\n",
       "      <td>software</td>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>information</td>\n",
       "      <td>services</td>\n",
       "      <td>banking</td>\n",
       "      <td>services</td>\n",
       "      <td>services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>computers</td>\n",
       "      <td>computers</td>\n",
       "      <td>management</td>\n",
       "      <td>computers</td>\n",
       "      <td>banking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>services</td>\n",
       "      <td>banks</td>\n",
       "      <td>computers</td>\n",
       "      <td>business</td>\n",
       "      <td>computers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>management</td>\n",
       "      <td>pacific</td>\n",
       "      <td>pacific</td>\n",
       "      <td>banking</td>\n",
       "      <td>management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>credit</td>\n",
       "      <td>banking</td>\n",
       "      <td>banks</td>\n",
       "      <td>internet</td>\n",
       "      <td>pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>regulation</td>\n",
       "      <td>design</td>\n",
       "      <td>networks</td>\n",
       "      <td>communications</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>technology</td>\n",
       "      <td>health</td>\n",
       "      <td>business</td>\n",
       "      <td>pacific</td>\n",
       "      <td>presidents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>securities</td>\n",
       "      <td>alliances</td>\n",
       "      <td>research</td>\n",
       "      <td>health</td>\n",
       "      <td>networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>government</td>\n",
       "      <td>electronics</td>\n",
       "      <td>marketing</td>\n",
       "      <td>networks</td>\n",
       "      <td>credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>profiles</td>\n",
       "      <td>profiles</td>\n",
       "      <td>income</td>\n",
       "      <td>credit</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>health</td>\n",
       "      <td>networks</td>\n",
       "      <td>design</td>\n",
       "      <td>design</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>marketing</td>\n",
       "      <td>engineering</td>\n",
       "      <td>presidents</td>\n",
       "      <td>marketing</td>\n",
       "      <td>banks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>costs</td>\n",
       "      <td>government</td>\n",
       "      <td>profiles</td>\n",
       "      <td>technology</td>\n",
       "      <td>marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>research</td>\n",
       "      <td>business</td>\n",
       "      <td>technology</td>\n",
       "      <td>presidents</td>\n",
       "      <td>companies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "year         1991         1992         1993            1994         1995\n",
       "rank                                                                    \n",
       "1      automation     industry     industry        industry     industry\n",
       "2           banks      systems   automation     information  information\n",
       "3         systems   automation     software         systems      systems\n",
       "4        industry     software      systems      automation   automation\n",
       "5         banking  information  information      management     software\n",
       "6        software   management     services        software     internet\n",
       "7     information     services      banking        services     services\n",
       "8       computers    computers   management       computers      banking\n",
       "9        services        banks    computers        business    computers\n",
       "10     management      pacific      pacific         banking   management\n",
       "11         credit      banking        banks        internet      pacific\n",
       "12     regulation       design     networks  communications     business\n",
       "13     technology       health     business         pacific   presidents\n",
       "14     securities    alliances     research          health     networks\n",
       "15     government  electronics    marketing        networks       credit\n",
       "16       profiles     profiles       income          credit  electronics\n",
       "17         health     networks       design          design       health\n",
       "18      marketing  engineering   presidents       marketing        banks\n",
       "19          costs   government     profiles      technology    marketing\n",
       "20       research     business   technology      presidents    companies"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>side</th>\n",
       "      <th colspan=\"5\" halign=\"left\">left</th>\n",
       "      <th colspan=\"5\" halign=\"left\">right</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>automation</td>\n",
       "      <td>industry</td>\n",
       "      <td>industry</td>\n",
       "      <td>industry</td>\n",
       "      <td>industry</td>\n",
       "      <td>automation</td>\n",
       "      <td>industry</td>\n",
       "      <td>industry</td>\n",
       "      <td>industry</td>\n",
       "      <td>industry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banks</td>\n",
       "      <td>systems</td>\n",
       "      <td>automation</td>\n",
       "      <td>information</td>\n",
       "      <td>information</td>\n",
       "      <td>banks</td>\n",
       "      <td>systems</td>\n",
       "      <td>automation</td>\n",
       "      <td>information</td>\n",
       "      <td>information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>systems</td>\n",
       "      <td>automation</td>\n",
       "      <td>software</td>\n",
       "      <td>systems</td>\n",
       "      <td>systems</td>\n",
       "      <td>systems</td>\n",
       "      <td>automation</td>\n",
       "      <td>software</td>\n",
       "      <td>systems</td>\n",
       "      <td>systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>industry</td>\n",
       "      <td>software</td>\n",
       "      <td>systems</td>\n",
       "      <td>automation</td>\n",
       "      <td>automation</td>\n",
       "      <td>industry</td>\n",
       "      <td>software</td>\n",
       "      <td>systems</td>\n",
       "      <td>automation</td>\n",
       "      <td>automation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>banking</td>\n",
       "      <td>information</td>\n",
       "      <td>information</td>\n",
       "      <td>management</td>\n",
       "      <td>software</td>\n",
       "      <td>banking</td>\n",
       "      <td>information</td>\n",
       "      <td>information</td>\n",
       "      <td>management</td>\n",
       "      <td>software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>software</td>\n",
       "      <td>management</td>\n",
       "      <td>services</td>\n",
       "      <td>software</td>\n",
       "      <td>internet</td>\n",
       "      <td>software</td>\n",
       "      <td>management</td>\n",
       "      <td>services</td>\n",
       "      <td>software</td>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>information</td>\n",
       "      <td>services</td>\n",
       "      <td>banking</td>\n",
       "      <td>services</td>\n",
       "      <td>services</td>\n",
       "      <td>information</td>\n",
       "      <td>services</td>\n",
       "      <td>banking</td>\n",
       "      <td>services</td>\n",
       "      <td>services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>computers</td>\n",
       "      <td>computers</td>\n",
       "      <td>management</td>\n",
       "      <td>computers</td>\n",
       "      <td>banking</td>\n",
       "      <td>computers</td>\n",
       "      <td>computers</td>\n",
       "      <td>management</td>\n",
       "      <td>computers</td>\n",
       "      <td>banking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>services</td>\n",
       "      <td>banks</td>\n",
       "      <td>computers</td>\n",
       "      <td>business</td>\n",
       "      <td>computers</td>\n",
       "      <td>services</td>\n",
       "      <td>banks</td>\n",
       "      <td>computers</td>\n",
       "      <td>business</td>\n",
       "      <td>computers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>management</td>\n",
       "      <td>pacific</td>\n",
       "      <td>pacific</td>\n",
       "      <td>banking</td>\n",
       "      <td>management</td>\n",
       "      <td>management</td>\n",
       "      <td>pacific</td>\n",
       "      <td>pacific</td>\n",
       "      <td>banking</td>\n",
       "      <td>management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>credit</td>\n",
       "      <td>banking</td>\n",
       "      <td>banks</td>\n",
       "      <td>internet</td>\n",
       "      <td>pacific</td>\n",
       "      <td>credit</td>\n",
       "      <td>banking</td>\n",
       "      <td>banks</td>\n",
       "      <td>internet</td>\n",
       "      <td>pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>regulation</td>\n",
       "      <td>design</td>\n",
       "      <td>networks</td>\n",
       "      <td>communications</td>\n",
       "      <td>business</td>\n",
       "      <td>regulation</td>\n",
       "      <td>design</td>\n",
       "      <td>networks</td>\n",
       "      <td>communications</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>technology</td>\n",
       "      <td>health</td>\n",
       "      <td>business</td>\n",
       "      <td>pacific</td>\n",
       "      <td>presidents</td>\n",
       "      <td>technology</td>\n",
       "      <td>health</td>\n",
       "      <td>business</td>\n",
       "      <td>pacific</td>\n",
       "      <td>presidents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>securities</td>\n",
       "      <td>alliances</td>\n",
       "      <td>research</td>\n",
       "      <td>health</td>\n",
       "      <td>networks</td>\n",
       "      <td>securities</td>\n",
       "      <td>alliances</td>\n",
       "      <td>research</td>\n",
       "      <td>health</td>\n",
       "      <td>networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>government</td>\n",
       "      <td>electronics</td>\n",
       "      <td>marketing</td>\n",
       "      <td>networks</td>\n",
       "      <td>credit</td>\n",
       "      <td>government</td>\n",
       "      <td>electronics</td>\n",
       "      <td>marketing</td>\n",
       "      <td>networks</td>\n",
       "      <td>credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>profiles</td>\n",
       "      <td>profiles</td>\n",
       "      <td>income</td>\n",
       "      <td>credit</td>\n",
       "      <td>electronics</td>\n",
       "      <td>profiles</td>\n",
       "      <td>profiles</td>\n",
       "      <td>income</td>\n",
       "      <td>credit</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>health</td>\n",
       "      <td>networks</td>\n",
       "      <td>design</td>\n",
       "      <td>design</td>\n",
       "      <td>health</td>\n",
       "      <td>health</td>\n",
       "      <td>networks</td>\n",
       "      <td>design</td>\n",
       "      <td>design</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>marketing</td>\n",
       "      <td>engineering</td>\n",
       "      <td>presidents</td>\n",
       "      <td>marketing</td>\n",
       "      <td>banks</td>\n",
       "      <td>marketing</td>\n",
       "      <td>engineering</td>\n",
       "      <td>presidents</td>\n",
       "      <td>marketing</td>\n",
       "      <td>banks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>costs</td>\n",
       "      <td>government</td>\n",
       "      <td>profiles</td>\n",
       "      <td>technology</td>\n",
       "      <td>marketing</td>\n",
       "      <td>costs</td>\n",
       "      <td>government</td>\n",
       "      <td>profiles</td>\n",
       "      <td>technology</td>\n",
       "      <td>marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>research</td>\n",
       "      <td>business</td>\n",
       "      <td>technology</td>\n",
       "      <td>presidents</td>\n",
       "      <td>companies</td>\n",
       "      <td>research</td>\n",
       "      <td>business</td>\n",
       "      <td>technology</td>\n",
       "      <td>presidents</td>\n",
       "      <td>companies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "side         left                                                         \\\n",
       "year         1991         1992         1993            1994         1995   \n",
       "rank                                                                       \n",
       "1      automation     industry     industry        industry     industry   \n",
       "2           banks      systems   automation     information  information   \n",
       "3         systems   automation     software         systems      systems   \n",
       "4        industry     software      systems      automation   automation   \n",
       "5         banking  information  information      management     software   \n",
       "6        software   management     services        software     internet   \n",
       "7     information     services      banking        services     services   \n",
       "8       computers    computers   management       computers      banking   \n",
       "9        services        banks    computers        business    computers   \n",
       "10     management      pacific      pacific         banking   management   \n",
       "11         credit      banking        banks        internet      pacific   \n",
       "12     regulation       design     networks  communications     business   \n",
       "13     technology       health     business         pacific   presidents   \n",
       "14     securities    alliances     research          health     networks   \n",
       "15     government  electronics    marketing        networks       credit   \n",
       "16       profiles     profiles       income          credit  electronics   \n",
       "17         health     networks       design          design       health   \n",
       "18      marketing  engineering   presidents       marketing        banks   \n",
       "19          costs   government     profiles      technology    marketing   \n",
       "20       research     business   technology      presidents    companies   \n",
       "\n",
       "side        right                                                         \n",
       "year         1991         1992         1993            1994         1995  \n",
       "rank                                                                      \n",
       "1      automation     industry     industry        industry     industry  \n",
       "2           banks      systems   automation     information  information  \n",
       "3         systems   automation     software         systems      systems  \n",
       "4        industry     software      systems      automation   automation  \n",
       "5         banking  information  information      management     software  \n",
       "6        software   management     services        software     internet  \n",
       "7     information     services      banking        services     services  \n",
       "8       computers    computers   management       computers      banking  \n",
       "9        services        banks    computers        business    computers  \n",
       "10     management      pacific      pacific         banking   management  \n",
       "11         credit      banking        banks        internet      pacific  \n",
       "12     regulation       design     networks  communications     business  \n",
       "13     technology       health     business         pacific   presidents  \n",
       "14     securities    alliances     research          health     networks  \n",
       "15     government  electronics    marketing        networks       credit  \n",
       "16       profiles     profiles       income          credit  electronics  \n",
       "17         health     networks       design          design       health  \n",
       "18      marketing  engineering   presidents       marketing        banks  \n",
       "19          costs   government     profiles      technology    marketing  \n",
       "20       research     business   technology      presidents    companies  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auto] value_col -> 'token' 로 대체했습니다.\n",
      "[auto] value_col -> 'token' 로 대체했습니다.\n",
      "[auto] value_col -> 'token' 로 대체했습니다.\n",
      "\n",
      "=== [PAPER] Applications▁of▁artificial▁intelligence : left / right / (left+right) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>year</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>physics</td>\n",
       "      <td>physics</td>\n",
       "      <td>physics</td>\n",
       "      <td>physics</td>\n",
       "      <td>physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>biology</td>\n",
       "      <td>management</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>biology</td>\n",
       "      <td>management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linguistics</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>biology</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>geometry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logic</td>\n",
       "      <td>geometry</td>\n",
       "      <td>geometry</td>\n",
       "      <td>logic</td>\n",
       "      <td>logic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>philosophy</td>\n",
       "      <td>biology</td>\n",
       "      <td>management</td>\n",
       "      <td>geometry</td>\n",
       "      <td>archaeology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>management</td>\n",
       "      <td>logic</td>\n",
       "      <td>logic</td>\n",
       "      <td>psychology</td>\n",
       "      <td>design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>geometry</td>\n",
       "      <td>psychology</td>\n",
       "      <td>science</td>\n",
       "      <td>space</td>\n",
       "      <td>biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>archaeology</td>\n",
       "      <td>language</td>\n",
       "      <td>learning</td>\n",
       "      <td>management</td>\n",
       "      <td>philosophy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>design</td>\n",
       "      <td>statistics</td>\n",
       "      <td>space</td>\n",
       "      <td>design</td>\n",
       "      <td>psychology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>psychology</td>\n",
       "      <td>linguistics</td>\n",
       "      <td>Population</td>\n",
       "      <td>science</td>\n",
       "      <td>learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>language</td>\n",
       "      <td>optics</td>\n",
       "      <td>systems</td>\n",
       "      <td>archaeology</td>\n",
       "      <td>language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>music</td>\n",
       "      <td>cybernetics</td>\n",
       "      <td>music</td>\n",
       "      <td>Data</td>\n",
       "      <td>linguistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cybernetics</td>\n",
       "      <td>space</td>\n",
       "      <td>psychology</td>\n",
       "      <td>Politics</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>education</td>\n",
       "      <td>design</td>\n",
       "      <td>Data</td>\n",
       "      <td>learning</td>\n",
       "      <td>Gene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>science</td>\n",
       "      <td>education</td>\n",
       "      <td>design</td>\n",
       "      <td>cybernetics</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>communication</td>\n",
       "      <td>music</td>\n",
       "      <td>archaeology</td>\n",
       "      <td>statistics</td>\n",
       "      <td>engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>space</td>\n",
       "      <td>Perception</td>\n",
       "      <td>statistics</td>\n",
       "      <td>Software</td>\n",
       "      <td>statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data</td>\n",
       "      <td>science</td>\n",
       "      <td>cybernetics</td>\n",
       "      <td>language</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>statistics</td>\n",
       "      <td>Gene</td>\n",
       "      <td>Politics</td>\n",
       "      <td>systems</td>\n",
       "      <td>systems</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "year           1991         1992         1993         1994         1995\n",
       "rank                                                                   \n",
       "1       mathematics  mathematics  mathematics  mathematics  mathematics\n",
       "2           physics      physics      physics      physics      physics\n",
       "3           biology   management   philosophy      biology   management\n",
       "4       linguistics   philosophy      biology   philosophy     geometry\n",
       "5             logic     geometry     geometry        logic        logic\n",
       "6        philosophy      biology   management     geometry  archaeology\n",
       "7        management        logic        logic   psychology       design\n",
       "8          geometry   psychology      science        space      biology\n",
       "9       archaeology     language     learning   management   philosophy\n",
       "10           design   statistics        space       design   psychology\n",
       "11       psychology  linguistics   Population      science     learning\n",
       "12         language       optics      systems  archaeology     language\n",
       "13            music  cybernetics        music         Data  linguistics\n",
       "14      cybernetics        space   psychology     Politics        music\n",
       "15        education       design         Data     learning         Gene\n",
       "16          science    education       design  cybernetics        noise\n",
       "17    communication        music  archaeology   statistics  engineering\n",
       "18            space   Perception   statistics     Software   statistics\n",
       "19             Data      science  cybernetics     language        space\n",
       "20       statistics         Gene     Politics      systems      systems"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>year</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>physics</td>\n",
       "      <td>physics</td>\n",
       "      <td>physics</td>\n",
       "      <td>physics</td>\n",
       "      <td>physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>biology</td>\n",
       "      <td>management</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>biology</td>\n",
       "      <td>management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linguistics</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>biology</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>geometry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logic</td>\n",
       "      <td>geometry</td>\n",
       "      <td>geometry</td>\n",
       "      <td>logic</td>\n",
       "      <td>logic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>philosophy</td>\n",
       "      <td>biology</td>\n",
       "      <td>management</td>\n",
       "      <td>geometry</td>\n",
       "      <td>archaeology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>management</td>\n",
       "      <td>logic</td>\n",
       "      <td>logic</td>\n",
       "      <td>psychology</td>\n",
       "      <td>design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>geometry</td>\n",
       "      <td>psychology</td>\n",
       "      <td>science</td>\n",
       "      <td>space</td>\n",
       "      <td>biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>archaeology</td>\n",
       "      <td>language</td>\n",
       "      <td>learning</td>\n",
       "      <td>management</td>\n",
       "      <td>philosophy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>design</td>\n",
       "      <td>statistics</td>\n",
       "      <td>space</td>\n",
       "      <td>design</td>\n",
       "      <td>psychology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>psychology</td>\n",
       "      <td>linguistics</td>\n",
       "      <td>Population</td>\n",
       "      <td>science</td>\n",
       "      <td>learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>language</td>\n",
       "      <td>optics</td>\n",
       "      <td>systems</td>\n",
       "      <td>archaeology</td>\n",
       "      <td>language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>music</td>\n",
       "      <td>cybernetics</td>\n",
       "      <td>music</td>\n",
       "      <td>Data</td>\n",
       "      <td>linguistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cybernetics</td>\n",
       "      <td>space</td>\n",
       "      <td>psychology</td>\n",
       "      <td>Politics</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>education</td>\n",
       "      <td>design</td>\n",
       "      <td>Data</td>\n",
       "      <td>learning</td>\n",
       "      <td>Gene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>science</td>\n",
       "      <td>education</td>\n",
       "      <td>design</td>\n",
       "      <td>cybernetics</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>communication</td>\n",
       "      <td>music</td>\n",
       "      <td>archaeology</td>\n",
       "      <td>statistics</td>\n",
       "      <td>engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>space</td>\n",
       "      <td>Perception</td>\n",
       "      <td>statistics</td>\n",
       "      <td>Software</td>\n",
       "      <td>statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data</td>\n",
       "      <td>science</td>\n",
       "      <td>cybernetics</td>\n",
       "      <td>language</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>statistics</td>\n",
       "      <td>Gene</td>\n",
       "      <td>Politics</td>\n",
       "      <td>systems</td>\n",
       "      <td>systems</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "year           1991         1992         1993         1994         1995\n",
       "rank                                                                   \n",
       "1       mathematics  mathematics  mathematics  mathematics  mathematics\n",
       "2           physics      physics      physics      physics      physics\n",
       "3           biology   management   philosophy      biology   management\n",
       "4       linguistics   philosophy      biology   philosophy     geometry\n",
       "5             logic     geometry     geometry        logic        logic\n",
       "6        philosophy      biology   management     geometry  archaeology\n",
       "7        management        logic        logic   psychology       design\n",
       "8          geometry   psychology      science        space      biology\n",
       "9       archaeology     language     learning   management   philosophy\n",
       "10           design   statistics        space       design   psychology\n",
       "11       psychology  linguistics   Population      science     learning\n",
       "12         language       optics      systems  archaeology     language\n",
       "13            music  cybernetics        music         Data  linguistics\n",
       "14      cybernetics        space   psychology     Politics        music\n",
       "15        education       design         Data     learning         Gene\n",
       "16          science    education       design  cybernetics        noise\n",
       "17    communication        music  archaeology   statistics  engineering\n",
       "18            space   Perception   statistics     Software   statistics\n",
       "19             Data      science  cybernetics     language        space\n",
       "20       statistics         Gene     Politics      systems      systems"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>side</th>\n",
       "      <th colspan=\"5\" halign=\"left\">left</th>\n",
       "      <th colspan=\"5\" halign=\"left\">right</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>physics</td>\n",
       "      <td>physics</td>\n",
       "      <td>physics</td>\n",
       "      <td>physics</td>\n",
       "      <td>physics</td>\n",
       "      <td>physics</td>\n",
       "      <td>physics</td>\n",
       "      <td>physics</td>\n",
       "      <td>physics</td>\n",
       "      <td>physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>biology</td>\n",
       "      <td>management</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>biology</td>\n",
       "      <td>management</td>\n",
       "      <td>biology</td>\n",
       "      <td>management</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>biology</td>\n",
       "      <td>management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linguistics</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>biology</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>geometry</td>\n",
       "      <td>linguistics</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>biology</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>geometry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logic</td>\n",
       "      <td>geometry</td>\n",
       "      <td>geometry</td>\n",
       "      <td>logic</td>\n",
       "      <td>logic</td>\n",
       "      <td>logic</td>\n",
       "      <td>geometry</td>\n",
       "      <td>geometry</td>\n",
       "      <td>logic</td>\n",
       "      <td>logic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>philosophy</td>\n",
       "      <td>biology</td>\n",
       "      <td>management</td>\n",
       "      <td>geometry</td>\n",
       "      <td>archaeology</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>biology</td>\n",
       "      <td>management</td>\n",
       "      <td>geometry</td>\n",
       "      <td>archaeology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>management</td>\n",
       "      <td>logic</td>\n",
       "      <td>logic</td>\n",
       "      <td>psychology</td>\n",
       "      <td>design</td>\n",
       "      <td>management</td>\n",
       "      <td>logic</td>\n",
       "      <td>logic</td>\n",
       "      <td>psychology</td>\n",
       "      <td>design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>geometry</td>\n",
       "      <td>psychology</td>\n",
       "      <td>science</td>\n",
       "      <td>space</td>\n",
       "      <td>biology</td>\n",
       "      <td>geometry</td>\n",
       "      <td>psychology</td>\n",
       "      <td>science</td>\n",
       "      <td>space</td>\n",
       "      <td>biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>archaeology</td>\n",
       "      <td>language</td>\n",
       "      <td>learning</td>\n",
       "      <td>management</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>archaeology</td>\n",
       "      <td>language</td>\n",
       "      <td>learning</td>\n",
       "      <td>management</td>\n",
       "      <td>philosophy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>design</td>\n",
       "      <td>statistics</td>\n",
       "      <td>space</td>\n",
       "      <td>design</td>\n",
       "      <td>psychology</td>\n",
       "      <td>design</td>\n",
       "      <td>statistics</td>\n",
       "      <td>space</td>\n",
       "      <td>design</td>\n",
       "      <td>psychology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>psychology</td>\n",
       "      <td>linguistics</td>\n",
       "      <td>Population</td>\n",
       "      <td>science</td>\n",
       "      <td>learning</td>\n",
       "      <td>psychology</td>\n",
       "      <td>linguistics</td>\n",
       "      <td>Population</td>\n",
       "      <td>science</td>\n",
       "      <td>learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>language</td>\n",
       "      <td>optics</td>\n",
       "      <td>systems</td>\n",
       "      <td>archaeology</td>\n",
       "      <td>language</td>\n",
       "      <td>language</td>\n",
       "      <td>optics</td>\n",
       "      <td>systems</td>\n",
       "      <td>archaeology</td>\n",
       "      <td>language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>music</td>\n",
       "      <td>cybernetics</td>\n",
       "      <td>music</td>\n",
       "      <td>Data</td>\n",
       "      <td>linguistics</td>\n",
       "      <td>music</td>\n",
       "      <td>cybernetics</td>\n",
       "      <td>music</td>\n",
       "      <td>Data</td>\n",
       "      <td>linguistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cybernetics</td>\n",
       "      <td>space</td>\n",
       "      <td>psychology</td>\n",
       "      <td>Politics</td>\n",
       "      <td>music</td>\n",
       "      <td>cybernetics</td>\n",
       "      <td>space</td>\n",
       "      <td>psychology</td>\n",
       "      <td>Politics</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>education</td>\n",
       "      <td>design</td>\n",
       "      <td>Data</td>\n",
       "      <td>learning</td>\n",
       "      <td>Gene</td>\n",
       "      <td>education</td>\n",
       "      <td>design</td>\n",
       "      <td>Data</td>\n",
       "      <td>learning</td>\n",
       "      <td>Gene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>science</td>\n",
       "      <td>education</td>\n",
       "      <td>design</td>\n",
       "      <td>cybernetics</td>\n",
       "      <td>noise</td>\n",
       "      <td>science</td>\n",
       "      <td>education</td>\n",
       "      <td>design</td>\n",
       "      <td>cybernetics</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>communication</td>\n",
       "      <td>music</td>\n",
       "      <td>archaeology</td>\n",
       "      <td>statistics</td>\n",
       "      <td>engineering</td>\n",
       "      <td>communication</td>\n",
       "      <td>music</td>\n",
       "      <td>archaeology</td>\n",
       "      <td>statistics</td>\n",
       "      <td>engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>space</td>\n",
       "      <td>Perception</td>\n",
       "      <td>statistics</td>\n",
       "      <td>Software</td>\n",
       "      <td>statistics</td>\n",
       "      <td>space</td>\n",
       "      <td>Perception</td>\n",
       "      <td>statistics</td>\n",
       "      <td>Software</td>\n",
       "      <td>statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data</td>\n",
       "      <td>science</td>\n",
       "      <td>cybernetics</td>\n",
       "      <td>language</td>\n",
       "      <td>space</td>\n",
       "      <td>Data</td>\n",
       "      <td>science</td>\n",
       "      <td>cybernetics</td>\n",
       "      <td>language</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>statistics</td>\n",
       "      <td>Gene</td>\n",
       "      <td>Politics</td>\n",
       "      <td>systems</td>\n",
       "      <td>systems</td>\n",
       "      <td>statistics</td>\n",
       "      <td>Gene</td>\n",
       "      <td>Politics</td>\n",
       "      <td>systems</td>\n",
       "      <td>systems</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "side           left                                                      \\\n",
       "year           1991         1992         1993         1994         1995   \n",
       "rank                                                                      \n",
       "1       mathematics  mathematics  mathematics  mathematics  mathematics   \n",
       "2           physics      physics      physics      physics      physics   \n",
       "3           biology   management   philosophy      biology   management   \n",
       "4       linguistics   philosophy      biology   philosophy     geometry   \n",
       "5             logic     geometry     geometry        logic        logic   \n",
       "6        philosophy      biology   management     geometry  archaeology   \n",
       "7        management        logic        logic   psychology       design   \n",
       "8          geometry   psychology      science        space      biology   \n",
       "9       archaeology     language     learning   management   philosophy   \n",
       "10           design   statistics        space       design   psychology   \n",
       "11       psychology  linguistics   Population      science     learning   \n",
       "12         language       optics      systems  archaeology     language   \n",
       "13            music  cybernetics        music         Data  linguistics   \n",
       "14      cybernetics        space   psychology     Politics        music   \n",
       "15        education       design         Data     learning         Gene   \n",
       "16          science    education       design  cybernetics        noise   \n",
       "17    communication        music  archaeology   statistics  engineering   \n",
       "18            space   Perception   statistics     Software   statistics   \n",
       "19             Data      science  cybernetics     language        space   \n",
       "20       statistics         Gene     Politics      systems      systems   \n",
       "\n",
       "side          right                                                      \n",
       "year           1991         1992         1993         1994         1995  \n",
       "rank                                                                     \n",
       "1       mathematics  mathematics  mathematics  mathematics  mathematics  \n",
       "2           physics      physics      physics      physics      physics  \n",
       "3           biology   management   philosophy      biology   management  \n",
       "4       linguistics   philosophy      biology   philosophy     geometry  \n",
       "5             logic     geometry     geometry        logic        logic  \n",
       "6        philosophy      biology   management     geometry  archaeology  \n",
       "7        management        logic        logic   psychology       design  \n",
       "8          geometry   psychology      science        space      biology  \n",
       "9       archaeology     language     learning   management   philosophy  \n",
       "10           design   statistics        space       design   psychology  \n",
       "11       psychology  linguistics   Population      science     learning  \n",
       "12         language       optics      systems  archaeology     language  \n",
       "13            music  cybernetics        music         Data  linguistics  \n",
       "14      cybernetics        space   psychology     Politics        music  \n",
       "15        education       design         Data     learning         Gene  \n",
       "16          science    education       design  cybernetics        noise  \n",
       "17    communication        music  archaeology   statistics  engineering  \n",
       "18            space   Perception   statistics     Software   statistics  \n",
       "19             Data      science  cybernetics     language        space  \n",
       "20       statistics         Gene     Politics      systems      systems  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== 한 셀로 실행: (1) news/artificial▁intelligence + (2) paper/Applications▁of▁artificial▁intelligence\n",
    "#       각각 left/right 를 \"연도=가로, rank=세로\" 표로 만들고 + left/right 합친 표까지 출력/저장 =====\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(\"./outputs/neighbor_mask\")\n",
    "\n",
    "# ----------------------------\n",
    "# 공통 유틸 (깔끔하게만; 최적: 공통 로더/피벗/세이브)\n",
    "# ----------------------------\n",
    "def load_neighbors(domain: str, target: str, years, side: str, k: int = 20, base_dir: Path = BASE_DIR) -> pd.DataFrame:\n",
    "    rows_all = []\n",
    "    for y in years:\n",
    "        p = base_dir / f\"{domain}_{y}_{target}_neighbors.json\"\n",
    "        obj = json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "        key = \"topk_left\" if side == \"left\" else \"topk_right\"\n",
    "        rows = obj.get(key, [])[:k]\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.insert(0, \"year\", y)\n",
    "        df.insert(1, \"domain\", domain)\n",
    "        df.insert(2, \"side\", side)\n",
    "        df.insert(3, \"rank\", range(1, len(df) + 1))\n",
    "        rows_all.append(df)\n",
    "    return pd.concat(rows_all, ignore_index=True) if rows_all else pd.DataFrame()\n",
    "\n",
    "def pivot_rank_year(df: pd.DataFrame, value_col: str = \"label\") -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        return df\n",
    "    if value_col not in df.columns:\n",
    "        # label이 없을 수도 있으니: 가장 그럴듯한 문자열 컬럼 자동 선택\n",
    "        candidates = [c for c in [\"label\", \"neighbor\", \"token\", \"name\", \"title\", \"text\", \"word\"] if c in df.columns]\n",
    "        if not candidates:\n",
    "            raise KeyError(f\"value_col='{value_col}' 없음. 가능한 컬럼: {list(df.columns)}\")\n",
    "        value_col = candidates[0]\n",
    "        print(f\"[auto] value_col -> '{value_col}' 로 대체했습니다.\")\n",
    "    return (\n",
    "        df.pivot(index=\"rank\", columns=\"year\", values=value_col)\n",
    "          .sort_index()\n",
    "          .sort_index(axis=1)\n",
    "    )\n",
    "\n",
    "def pivot_rank_year_lr(left_df: pd.DataFrame, right_df: pd.DataFrame, value_col: str = \"label\") -> pd.DataFrame:\n",
    "    if left_df.empty and right_df.empty:\n",
    "        return pd.DataFrame()\n",
    "    all_df = pd.concat([left_df, right_df], ignore_index=True)\n",
    "    # value_col 자동 보정은 pivot_rank_year에서 했던 로직 재사용\n",
    "    if value_col not in all_df.columns:\n",
    "        candidates = [c for c in [\"label\", \"neighbor\", \"token\", \"name\", \"title\", \"text\", \"word\"] if c in all_df.columns]\n",
    "        if not candidates:\n",
    "            raise KeyError(f\"value_col='{value_col}' 없음. 가능한 컬럼: {list(all_df.columns)}\")\n",
    "        value_col = candidates[0]\n",
    "        print(f\"[auto] value_col -> '{value_col}' 로 대체했습니다.\")\n",
    "    return (\n",
    "        all_df.pivot(index=\"rank\", columns=[\"side\", \"year\"], values=value_col)\n",
    "              .sort_index()\n",
    "              .sort_index(axis=1)\n",
    "    )\n",
    "\n",
    "def save_tables(prefix: str, left_tbl: pd.DataFrame, right_tbl: pd.DataFrame, lr_tbl: pd.DataFrame):\n",
    "    left_tbl.to_csv(f\"{prefix}_left_rank_by_year.csv\", encoding=\"utf-8-sig\")\n",
    "    right_tbl.to_csv(f\"{prefix}_right_rank_by_year.csv\", encoding=\"utf-8-sig\")\n",
    "    lr_tbl.to_csv(f\"{prefix}_lr_rank_by_year.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "# ----------------------------\n",
    "# 작업 1) news / artificial▁intelligence\n",
    "# ----------------------------\n",
    "years = [1991, 1992, 1993, 1994, 1995]\n",
    "target_news = \"artificial▁intelligence\"\n",
    "domain_news = \"news\"\n",
    "k = 20\n",
    "\n",
    "news_left_df  = load_neighbors(domain_news, target_news, years, \"left\",  k=k)\n",
    "news_right_df = load_neighbors(domain_news, target_news, years, \"right\", k=k)\n",
    "\n",
    "# 원본 확인(원하면 주석 해제)\n",
    "# display(news_left_df.head(30))\n",
    "# display(news_right_df.head(30))\n",
    "\n",
    "news_left_tbl  = pivot_rank_year(news_left_df,  value_col=\"label\")\n",
    "news_right_tbl = pivot_rank_year(news_right_df, value_col=\"label\")\n",
    "news_lr_tbl    = pivot_rank_year_lr(news_left_df, news_right_df, value_col=\"label\")\n",
    "\n",
    "print(\"\\n=== [NEWS] artificial▁intelligence : left / right / (left+right) ===\")\n",
    "display(news_left_tbl)\n",
    "display(news_right_tbl)\n",
    "display(news_lr_tbl)\n",
    "\n",
    "save_tables(prefix=\"news_artificial_intelligence\", left_tbl=news_left_tbl, right_tbl=news_right_tbl, lr_tbl=news_lr_tbl)\n",
    "\n",
    "# ----------------------------\n",
    "# 작업 2) paper / Applications▁of▁artificial▁intelligence\n",
    "# ----------------------------\n",
    "target_paper = \"Applications▁of▁artificial▁intelligence\"\n",
    "domain_paper = \"paper\"\n",
    "\n",
    "paper_left_df  = load_neighbors(domain_paper, target_paper, years, \"left\",  k=k)\n",
    "paper_right_df = load_neighbors(domain_paper, target_paper, years, \"right\", k=k)\n",
    "\n",
    "# 원본 확인(원하면 주석 해제)\n",
    "# display(paper_left_df.head(30))\n",
    "# display(paper_right_df.head(30))\n",
    "\n",
    "paper_left_tbl  = pivot_rank_year(paper_left_df,  value_col=\"label\")\n",
    "paper_right_tbl = pivot_rank_year(paper_right_df, value_col=\"label\")\n",
    "paper_lr_tbl    = pivot_rank_year_lr(paper_left_df, paper_right_df, value_col=\"label\")\n",
    "\n",
    "print(\"\\n=== [PAPER] Applications▁of▁artificial▁intelligence : left / right / (left+right) ===\")\n",
    "display(paper_left_tbl)\n",
    "display(paper_right_tbl)\n",
    "display(paper_lr_tbl)\n",
    "\n",
    "save_tables(prefix=\"paper_applications_of_artificial_intelligence\", left_tbl=paper_left_tbl, right_tbl=paper_right_tbl, lr_tbl=paper_lr_tbl)\n",
    "\n",
    "# print(\"\\nSaved CSVs:\")\n",
    "# print(\"- news_artificial_intelligence_left_rank_by_year.csv\")\n",
    "# print(\"- news_artificial_intelligence_right_rank_by_year.csv\")\n",
    "# print(\"- news_artificial_intelligence_lr_rank_by_year.csv\")\n",
    "# print(\"- paper_applications_of_artificial_intelligence_left_rank_by_year.csv\")\n",
    "# print(\"- paper_applications_of_artificial_intelligence_right_rank_by_year.csv\")\n",
    "# print(\"- paper_applications_of_artificial_intelligence_lr_rank_by_year.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3db229c1-2141-43cd-90b4-97930b6c8890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] wrote -> ./outputs/divergence/ai_neighbors_news_vs_paper.csv (rows=10)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python scripts/compute_divergence_v5.py \\\n",
    "  --in_root ./outputs/neighbor_mask \\\n",
    "  --out_csv ./outputs/divergence/ai_neighbors_news_vs_paper.csv \\\n",
    "  --years 1991 1992 1993 1994 1995 \\\n",
    "  --news_target artificial_intelligence \\\n",
    "  --paper_target Applications_of_artificial_intelligence \\\n",
    "  --side both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b712cb6-b91a-41a9-bab4-84701815775b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'outputs/neighbor_mask/news_1991_information_neighbors.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m domain_news \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnews\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m---> 74\u001b[0m news_left_df  \u001b[38;5;241m=\u001b[39m \u001b[43mload_neighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdomain_news\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_news\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myears\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m news_right_df \u001b[38;5;241m=\u001b[39m load_neighbors(domain_news, target_news, years, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m, k\u001b[38;5;241m=\u001b[39mk)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# 원본 확인(원하면 주석 해제)\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# display(news_left_df.head(30))\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# display(news_right_df.head(30))\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 17\u001b[0m, in \u001b[0;36mload_neighbors\u001b[0;34m(domain, target, years, side, k, base_dir)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m years:\n\u001b[1;32m     16\u001b[0m     p \u001b[38;5;241m=\u001b[39m base_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdomain\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_neighbors.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m     obj \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     18\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopk_left\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m side \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopk_right\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m     rows \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mget(key, [])[:k]\n",
      "File \u001b[0;32m/usr/lib/python3.10/pathlib.py:1134\u001b[0m, in \u001b[0;36mPath.read_text\u001b[0;34m(self, encoding, errors)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;124;03mOpen the file in text mode, read it, and close the file.\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[0;32m-> 1134\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/usr/lib/python3.10/pathlib.py:1119\u001b[0m, in \u001b[0;36mPath.open\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1118\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[0;32m-> 1119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'outputs/neighbor_mask/news_1991_information_neighbors.json'"
     ]
    }
   ],
   "source": [
    "# ===== 한 셀로 실행: (1) news/artificial▁intelligence + (2) paper/Applications▁of▁artificial▁intelligence\n",
    "#       각각 left/right 를 \"연도=가로, rank=세로\" 표로 만들고 + left/right 합친 표까지 출력/저장 =====\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(\"./outputs/neighbor_mask\")\n",
    "\n",
    "# ----------------------------\n",
    "# 공통 유틸 (깔끔하게만; 최적: 공통 로더/피벗/세이브)\n",
    "# ----------------------------\n",
    "def load_neighbors(domain: str, target: str, years, side: str, k: int = 20, base_dir: Path = BASE_DIR) -> pd.DataFrame:\n",
    "    rows_all = []\n",
    "    for y in years:\n",
    "        p = base_dir / f\"{domain}_{y}_{target}_neighbors.json\"\n",
    "        obj = json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "        key = \"topk_left\" if side == \"left\" else \"topk_right\"\n",
    "        rows = obj.get(key, [])[:k]\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.insert(0, \"year\", y)\n",
    "        df.insert(1, \"domain\", domain)\n",
    "        df.insert(2, \"side\", side)\n",
    "        df.insert(3, \"rank\", range(1, len(df) + 1))\n",
    "        rows_all.append(df)\n",
    "    return pd.concat(rows_all, ignore_index=True) if rows_all else pd.DataFrame()\n",
    "\n",
    "def pivot_rank_year(df: pd.DataFrame, value_col: str = \"label\") -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        return df\n",
    "    if value_col not in df.columns:\n",
    "        # label이 없을 수도 있으니: 가장 그럴듯한 문자열 컬럼 자동 선택\n",
    "        candidates = [c for c in [\"label\", \"neighbor\", \"token\", \"name\", \"title\", \"text\", \"word\"] if c in df.columns]\n",
    "        if not candidates:\n",
    "            raise KeyError(f\"value_col='{value_col}' 없음. 가능한 컬럼: {list(df.columns)}\")\n",
    "        value_col = candidates[0]\n",
    "        print(f\"[auto] value_col -> '{value_col}' 로 대체했습니다.\")\n",
    "    return (\n",
    "        df.pivot(index=\"rank\", columns=\"year\", values=value_col)\n",
    "          .sort_index()\n",
    "          .sort_index(axis=1)\n",
    "    )\n",
    "\n",
    "def pivot_rank_year_lr(left_df: pd.DataFrame, right_df: pd.DataFrame, value_col: str = \"label\") -> pd.DataFrame:\n",
    "    if left_df.empty and right_df.empty:\n",
    "        return pd.DataFrame()\n",
    "    all_df = pd.concat([left_df, right_df], ignore_index=True)\n",
    "    # value_col 자동 보정은 pivot_rank_year에서 했던 로직 재사용\n",
    "    if value_col not in all_df.columns:\n",
    "        candidates = [c for c in [\"label\", \"neighbor\", \"token\", \"name\", \"title\", \"text\", \"word\"] if c in all_df.columns]\n",
    "        if not candidates:\n",
    "            raise KeyError(f\"value_col='{value_col}' 없음. 가능한 컬럼: {list(all_df.columns)}\")\n",
    "        value_col = candidates[0]\n",
    "        print(f\"[auto] value_col -> '{value_col}' 로 대체했습니다.\")\n",
    "    return (\n",
    "        all_df.pivot(index=\"rank\", columns=[\"side\", \"year\"], values=value_col)\n",
    "              .sort_index()\n",
    "              .sort_index(axis=1)\n",
    "    )\n",
    "\n",
    "def save_tables(prefix: str, left_tbl: pd.DataFrame, right_tbl: pd.DataFrame, lr_tbl: pd.DataFrame):\n",
    "    left_tbl.to_csv(f\"{prefix}_left_rank_by_year.csv\", encoding=\"utf-8-sig\")\n",
    "    right_tbl.to_csv(f\"{prefix}_right_rank_by_year.csv\", encoding=\"utf-8-sig\")\n",
    "    lr_tbl.to_csv(f\"{prefix}_lr_rank_by_year.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "# ----------------------------\n",
    "# 작업 1) news / artificial▁intelligence\n",
    "# ----------------------------\n",
    "years = [1991, 1992, 1993, 1994, 1995]\n",
    "target_news = \"information\"\n",
    "domain_news = \"news\"\n",
    "k = 20\n",
    "\n",
    "news_left_df  = load_neighbors(domain_news, target_news, years, \"left\",  k=k)\n",
    "news_right_df = load_neighbors(domain_news, target_news, years, \"right\", k=k)\n",
    "\n",
    "# 원본 확인(원하면 주석 해제)\n",
    "# display(news_left_df.head(30))\n",
    "# display(news_right_df.head(30))\n",
    "\n",
    "news_left_tbl  = pivot_rank_year(news_left_df,  value_col=\"label\")\n",
    "news_right_tbl = pivot_rank_year(news_right_df, value_col=\"label\")\n",
    "# news_lr_tbl    = pivot_rank_year_lr(news_left_df, news_right_df, value_col=\"label\")\n",
    "\n",
    "print(\"\\n=== [NEWS] artificial▁intelligence : left / right / (left+right) ===\")\n",
    "display(news_left_tbl)\n",
    "display(news_right_tbl)\n",
    "# display(news_lr_tbl)\n",
    "\n",
    "save_tables(prefix=\"news_artificial_intelligence\", left_tbl=news_left_tbl, right_tbl=news_right_tbl, lr_tbl=news_lr_tbl)\n",
    "\n",
    "# ----------------------------\n",
    "# 작업 2) paper / Applications▁of▁artificial▁intelligence\n",
    "# ----------------------------\n",
    "target_paper = \"information\"\n",
    "domain_paper = \"paper\"\n",
    "\n",
    "paper_left_df  = load_neighbors(domain_paper, target_paper, years, \"left\",  k=k)\n",
    "paper_right_df = load_neighbors(domain_paper, target_paper, years, \"right\", k=k)\n",
    "\n",
    "# 원본 확인(원하면 주석 해제)\n",
    "# display(paper_left_df.head(30))\n",
    "# display(paper_right_df.head(30))\n",
    "\n",
    "paper_left_tbl  = pivot_rank_year(paper_left_df,  value_col=\"label\")\n",
    "paper_right_tbl = pivot_rank_year(paper_right_df, value_col=\"label\")\n",
    "# paper_lr_tbl    = pivot_rank_year_lr(paper_left_df, paper_right_df, value_col=\"label\")\n",
    "\n",
    "print(\"\\n=== [PAPER] Applications▁of▁artificial▁intelligence : left / right / (left+right) ===\")\n",
    "display(paper_left_tbl)\n",
    "display(paper_right_tbl)\n",
    "# display(paper_lr_tbl)\n",
    "\n",
    "save_tables(prefix=\"paper_applications_of_artificial_intelligence\", left_tbl=paper_left_tbl, right_tbl=paper_right_tbl, lr_tbl=paper_lr_tbl)\n",
    "\n",
    "# print(\"\\nSaved CSVs:\")\n",
    "# print(\"- news_artificial_intelligence_left_rank_by_year.csv\")\n",
    "# print(\"- news_artificial_intelligence_right_rank_by_year.csv\")\n",
    "# print(\"- news_artificial_intelligence_lr_rank_by_year.csv\")\n",
    "# print(\"- paper_applications_of_artificial_intelligence_left_rank_by_year.csv\")\n",
    "# print(\"- paper_applications_of_artificial_intelligence_right_rank_by_year.csv\")\n",
    "# print(\"- paper_applications_of_artificial_intelligence_lr_rank_by_year.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d27677b-6a61-4716-be15-dc1c95b5bc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to outputs/common_1995_tokens.txt\n",
      "num common tokens: 0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "out_dir = Path(\"./outputs\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def token_set_from_corpus(path):\n",
    "    tokens = set()\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            for tok in line.strip().split():\n",
    "                if tok:\n",
    "                    tokens.add(tok)\n",
    "    return tokens\n",
    "\n",
    "# load token sets\n",
    "news_tokens  = token_set_from_corpus(\"./corpus/news_1995.txt\")\n",
    "paper_tokens = token_set_from_corpus(\"./corpus/paper_1995.txt\")\n",
    "\n",
    "# intersection\n",
    "common_tokens = sorted(news_tokens & paper_tokens)\n",
    "\n",
    "# save\n",
    "out_path = out_dir / \"common_1995_tokens.txt\"\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for t in common_tokens:\n",
    "        f.write(t + \"\\n\")\n",
    "\n",
    "print(f\"saved to {out_path}\")\n",
    "print(\"num common tokens:\", len(common_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d126d85-c4cc-48a8-b0a2-470ee64e8937",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./outputs/common_1995_tokens.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in zip(range(50), f):\n",
    "        print(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df0ba4-4812-4dbe-bf75-5775e391d580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
